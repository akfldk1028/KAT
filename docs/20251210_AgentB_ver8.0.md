# Agent B (안심 가드) ver8.0 - 최종 기획서

**작성일**: 2025-12-10
**버전**: v8.0 (Simple 3-Stage Pipeline)
**상태**: 최종 설계 명세서

**주요 변경사항 (v7.0 → v8.0)**:
- ✅ **구조 단순화**: ReAct Loop → Simple 3-Stage Pipeline
- ✅ **근거 명확화**: 모든 수식에 학술적/통계적 근거
- ✅ **AI 자율성 강화**: Stage 2에 Kanana Agent 맥락 분석 추가 ⭐
- ✅ **설명 강화**: Kanana LLM이 단계별 판단 근거 설명
- ✅ **성능 개선**: 150ms → <100ms
- ✅ **복잡도 감소**: Bayesian 가중 평균 제거, Rule 기반 우선

---

## 목차

1. [개요 및 역할](#1-개요-및-역할)
2. [핵심 아키텍처: Simple 3-Stage Pipeline](#2-핵심-아키텍처-simple-3-stage-pipeline)
3. [스미싱 9개 유형 분류](#3-스미싱-9개-유형-분류)
4. [Stage별 상세 명세](#4-stage별-상세-명세)
5. [설명 생성 (XAI)](#5-설명-생성-xai)
6. [실제 동작 예제](#6-실제-동작-예제)
7. [성능 및 평가](#7-성능-및-평가)
8. [경쟁 평가 기준 충족](#8-경쟁-평가-기준-충족)
9. [학술적 근거](#9-학술적-근거)
10. [구현 로드맵](#10-구현-로드맵)
11. [참고 문헌](#11-참고-문헌)

---

## 1. 개요 및 역할

### 1.1 Agent B란?

**정의**: Kanana LLM 기반 **3-Stage 스미싱 탐지 시스템**

**핵심 철학**:
- **Rule First**: 빠르게 판단 가능한 것은 Rule 기반 (DB 조회)
- **Pattern Second**: 정부 통계 기반 9개 유형 분류
- **AI Last**: Kanana LLM이 맥락 분석 + 설명 생성

**차별점**:

```
┌─────────────────────────────────────────────────────────┐
│ 기존 시스템 (Complex AI-driven)                          │
├─────────────────────────────────────────────────────────┤
│ • ReAct Loop (5 사이클)                                  │
│ • Bayesian 가중 평균                                     │
│ • 동적 가중치 조정 (4가지 Case)                          │
│ • 복잡도 높음, 근거 불명확                               │
└─────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────┐
│ Agent B ver8.0 (Simple 3-Stage Pipeline)                │
├─────────────────────────────────────────────────────────┤
│ Stage 1: Rule-based (DB 블랙리스트)    → <10ms          │
│ Stage 2: Pattern Matching (9개 유형)   → <50ms          │
│ Stage 3: Kanana LLM (맥락 분석 + 설명) → <100ms         │
│ • 단순 명확, 모든 단계 근거 명시                         │
└─────────────────────────────────────────────────────────┘
```

### 1.2 핵심 역할

**Who (대상)**:
- 카카오톡 사용자 5천만명
- 일간 1천만 메시지 교환
- 연간 피싱 피해 3천억원

**What (기능)**:
1. **3-Stage 탐지**: Rule → Pattern → LLM
2. **9개 유형 분류**: A-1~C-3 (정부 통계 기반)
3. **투명한 설명**: 단계별 판단 근거 제시
4. **행동 권장**: "직접 전화 확인", "절대 송금 금지"

**Why (필요성)**:
- 기존 복잡한 AI 시스템: 근거 불명확, 느림 (150ms)
- Simple 3-Stage: 빠름 (<100ms), 근거 명확, 설명 가능

### 1.3 목표 지표

| 지표 | 기존 시스템 | ver8.0 목표 | 개선율 |
|------|------------|------------|--------|
| 응답 속도 | 150ms | **<100ms** (90% 케이스 10ms) | **-33%** |
| 미탐률 (FN) | 18% | **<8%** | **-55%** |
| 오탐률 (FP) | 12% | **<5%** | **-58%** |
| 설명 이해도 | 60% | **>90%** | **+50%** |
| 유형 인식률 | - | **>85%** (9개 유형) | **신규** |

---

## 2. 핵심 아키텍처: Simple 3-Stage Pipeline

### 2.1 전체 흐름도

```
[입력] 카카오톡 메시지
   ↓
┌─────────────────────────────────────────────────────────┐
│  Stage 1: Rule-based 빠른 필터링 (<10ms)                 │
│  ────────────────────────────────────────────────────   │
│  ✅ DB 블랙리스트 확인 (계좌/URL/전화번호)                │
│  └─ HIT → 즉시 CRITICAL 판정 + 종료                     │
│  └─ MISS → Stage 2로 진행                               │
└─────────────────────────────────────────────────────────┘
   ↓
┌─────────────────────────────────────────────────────────┐
│  Stage 2: Pattern Matching (9개 유형, <50ms)            │
│  ────────────────────────────────────────────────────   │
│  ✅ 정부 통계 기반 9개 유형 키워드 매칭                   │
│  └─ 매칭 → 카테고리 + 증거 → Stage 3                    │
│  └─ 미매칭 (NORMAL) → SAFE 판정 + 종료                  │
└─────────────────────────────────────────────────────────┘
   ↓
┌─────────────────────────────────────────────────────────┐
│  Stage 3: Kanana LLM 최종 검증 + 설명 (<100ms)          │
│  ────────────────────────────────────────────────────   │
│  ✅ Stage 1/2 결과 종합 분석                             │
│  ✅ 대화 이력 맥락 고려 (금감원 통계)                     │
│  ✅ 최근 유사 사례 검색 (RAG)                            │
│  ✅ 단계별 판단 근거 설명 생성                           │
│  └─ 최종 위험도 + 상세 설명 반환                         │
└─────────────────────────────────────────────────────────┘
   ↓
[출력] 위험도 + 단계별 설명 + 권장 행동
```

### 2.2 성능 분포

| Stage | 케이스 비율 | 처리 시간 | 누적 비율 |
|-------|------------|----------|----------|
| Stage 1 종료 (CRITICAL) | 5% | <10ms | 5% |
| Stage 2 종료 (SAFE) | 85% | <50ms | 90% |
| Stage 3 최종 검증 | 10% | <100ms | 100% |

**평균 응답 속도**: 5% × 10ms + 85% × 50ms + 10% × 100ms = **53ms**

### 2.3 AI의 역할 (Stage 3만)

**Kanana LLM의 역할**:
1. **맥락 이해**: 대화 이력, 유사 사례를 고려한 종합 판단
2. **설명 생성**: 단계별 판단 근거를 투명하게 설명
3. **보수적 판단**: 불확실성 높을 때 경고 (SUSPICIOUS)

**Rule/Pattern의 역할 (Stage 1/2)**:
- 빠르고 명확한 판단 (DB 조회, 키워드 매칭)
- 90% 케이스를 AI 없이 처리

---

## 3. 스미싱 9개 유형 분류

### 3.1 분류 체계

**출처**: 금융감독원 (2023), KISA (2024), 경찰청 (2022-2023)

| 대분류 | 코드 | 카테고리 | 대표 패턴 | 정부 통계 |
|--------|------|---------|----------|----------|
| **A: 개인 사칭** | A-1 | 지인 및 가족 사칭 | 액정 파손, 급전 | 금감원 2023: **33.7%** |
| | A-2 | 경조사 빙자 | 청첩장, 부고장 | KISA 2023: **1.7만건** |
| | A-3 | 로맨스 스캠 | 이성 교제 금전 | 경찰청 2023: 신종 |
| **B: 기관 사칭** | B-1 | 수사/금융 기관 | 검찰, 금감원 | 경찰청 2022: **78%** |
| | B-2 | 공공 행정 알림 | 건강검진, 과태료 | 경찰청 2023: **19.7배↑** |
| | B-3 | 택배/물류 | 배송 지연, 주소 불명 | KISA: **65%** (28만건) |
| **C: 경제 유인** | C-1 | 대출 빙자 | 저금리, 정부지원 | 금감원 2023: **35.2%** |
| | C-2 | 투자 리딩방 | 코인, 주식 고수익 | 국수본: **5,340억** |
| | C-3 | 몸캠 피싱 | 영상통화 협박 | 경찰청: 공식 분류 |

### 3.2 NORMAL (정상 메시지)

**정의**: 9개 스미싱 패턴에 해당하지 않는 일상 대화

**예시**:
- "오늘 저녁 뭐 먹을까?"
- "회의 시간 3시로 변경됐어"
- "생일 축하해! 🎉"

---

## 4. Stage별 상세 명세

### 4.1 Stage 1: Rule-based Filter

**목적**: DB 블랙리스트 확인으로 즉시 판정

**입력**: 메시지 텍스트

**처리 과정**:

```python
def stage1_rule_based(message: str) -> dict:
    """
    DB 블랙리스트 확인

    근거: 신고 이력 = 팩트 (객관적 증거)
    """

    # 1. 엔티티 추출 (정규식)
    entities = extract_entities(message)
    # - 계좌번호: (\d{2,3})-(\d{3,6})-(\d{4,8})
    # - URL: (https?://)?([a-z0-9\-\.]+\.[a-z]{2,})
    # - 전화번호: (01[0-9])-?(\d{3,4})-?(\d{4})

    # 2. DB 조회 (우선순위)
    sources = [
        ("금융감독원", 0.4),      # 공식 신고
        ("경찰청", 0.3),           # 범죄 수사
        ("민간 플랫폼", 0.2),      # 더치트, 후후
        ("통신사", 0.1)            # SKT, KT, LG
    ]

    for entity in entities:
        for source, weight in sources:
            result = query_blacklist(entity, source)
            if result["found"]:
                return {
                    "stage": 1,
                    "decision": "CRITICAL",
                    "entity": entity,
                    "report_count": result["count"],
                    "source": source,
                    "terminate": True  # 즉시 종료
                }

    # 3. DB에 없음 → Stage 2로
    return {"stage": 1, "continue": True}
```

**출력**:

```json
{
  "stage": 1,
  "decision": "CRITICAL" | null,
  "entity": "110-123-456789",
  "report_count": 342,
  "source": "금융감독원",
  "terminate": true | false
}
```

**학술적 근거**: Rule-based Expert System (Buchanan & Shortliffe, 1984)

---

### 4.2 Stage 2: Pattern Matching (9개 유형)

**목적**: 정부 통계 기반 9개 유형 분류

**입력**: 메시지 텍스트

**처리 과정**:

```python
def stage2_pattern_matching(message: str) -> dict:
    """
    9개 유형 키워드 매칭

    근거: 금감원/KISA/경찰청 통계 기반 분류
    """

    # 9개 유형 키워드 DB (Tier 구조)
    patterns = {
        "A-1": {
            "name": "지인 및 가족 사칭",
            "keywords": {
                "tier1": ["엄마", "아빠", "형", "언니", "오빠"],  # 핵심
                "tier2": ["폰 고장", "액정", "번호 바뀜", "급해"],  # 보조
                "tier3": ["급전", "학원비", "병원비", "계좌"]      # 맥락
            },
            "weight": 0.337,  # 금감원 2023: 33.7%
            "source": "금감원 2023: 가족사칭 33.7%"
        },
        # ... A-2 ~ C-3 (총 9개)
    }

    # Tier별 매칭 점수 계산
    tier_weights = {"tier1": 1.0, "tier2": 0.7, "tier3": 0.5}

    matches = {}
    for code, config in patterns.items():
        matched_keywords = []
        tier_scores = []

        for tier, keywords in config["keywords"].items():
            hits = [kw for kw in keywords if kw in message]
            if hits:
                matched_keywords.extend(hits)
                tier_scores.append(len(hits) * tier_weights[tier])

        if matched_keywords:
            # 매칭 강도 계산
            total_kw = sum(len(kws) for kws in config["keywords"].values())
            strength = sum(tier_scores) / total_kw

            matches[code] = {
                "name": config["name"],
                "score": strength * config["weight"],
                "matched_keywords": matched_keywords,
                "government_source": config["source"]
            }

    # 최고 점수 유형 선택
    if matches:
        best = max(matches, key=lambda k: matches[k]["score"])
        return {
            "stage": 2,
            "category": best,
            "matched_keywords": matches[best]["matched_keywords"],
            "government_source": matches[best]["government_source"],
            "all_matches": matches,
            "continue": True  # Stage 3로
        }
    else:
        # NORMAL (정상 메시지)
        return {
            "stage": 2,
            "category": "NORMAL",
            "decision": "SAFE",
            "terminate": True
        }
```

**출력**:

```json
{
  "stage": 2,
  "category": "A-1",
  "matched_keywords": ["엄마", "폰 고장", "급해"],
  "government_source": "금감원 2023: 가족사칭 33.7%",
  "all_matches": { ... },
  "continue": true
}
```

**학술적 근거**:
- Keyword Matching: Luhn (1958), "A Statistical Approach to Mechanized Encoding"
- TF-IDF (향후 개선): Sparck Jones (1972)

---

### 4.3 Stage 3: Kanana LLM 최종 검증 + 설명

**목적**: 맥락 분석 + 단계별 설명 생성

**입력**: Stage 1/2 결과 + 컨텍스트

**처리 과정**:

```python
def stage3_llm_verification(
    message: str,
    stage1: dict,
    stage2: dict
) -> dict:
    """
    Kanana LLM 최종 판단 + 설명 생성

    근거: LLM-as-Judge (Zheng et al., 2023)
    """

    # 1. 컨텍스트 수집
    context = {
        "history": get_conversation_history(sender_id),
        "similar_cases": search_recent_cases(
            text=message,
            category=stage2["category"],
            days=30,
            top_k=5
        )
    }

    # 2. Kanana LLM 프롬프트
    prompt = f"""
당신은 스미싱 탐지 전문가입니다. 아래 증거를 바탕으로 최종 판단과 설명을 제공하세요.

## 입력 정보
메시지: "{message}"

### Stage 1 결과 (DB 조회)
{format_stage1(stage1)}

### Stage 2 결과 (9개 유형 분류)
카테고리: {stage2['category']} ({stage2['government_source']})
매칭 키워드: {stage2['matched_keywords']}

### 대화 이력
기간: {context['history']['days']}일
메시지 수: {context['history']['count']}개
연락처 저장: {context['history']['is_saved']}

### 유사 사례 (최근 30일)
{format_similar_cases(context['similar_cases'])}

## 요구사항
다음 형식으로 JSON 응답하세요:

{{
  "risk_level": "SAFE | SUSPICIOUS | DANGEROUS | CRITICAL",
  "confidence": 0.0~1.0,
  "summary": "한 문장 핵심 근거",
  "stage1_analysis": "Stage 1 결과 해석",
  "stage2_analysis": "Stage 2 결과 해석",
  "history_analysis": "대화 이력 해석 (금감원 통계 인용)",
  "similar_cases_analysis": "유사 사례 해석",
  "final_reasoning": "종합 판단 근거",
  "recommended_action": {{
    "do": ["행동 1", "행동 2"],
    "dont": ["금지 1", "금지 2"]
  }}
}}
"""

    # 3. Kanana LLM 호출
    response = kanana_llm.generate(prompt)
    result = json.loads(response)

    # 4. 구조화된 출력
    return {
        "stage": 3,
        "final_risk": result["risk_level"],
        "confidence": result["confidence"],
        "explanation": {
            "summary": result["summary"],
            "stage1": result["stage1_analysis"],
            "stage2": result["stage2_analysis"],
            "history": result["history_analysis"],
            "similar_cases": result["similar_cases_analysis"],
            "final_reasoning": result["final_reasoning"],
            "recommended_action": result["recommended_action"]
        }
    }
```

**출력**:

```json
{
  "stage": 3,
  "final_risk": "DANGEROUS",
  "confidence": 0.85,
  "explanation": {
    "summary": "가족 사칭 스미싱으로 의심됩니다 (금감원 통계 33.7%)",
    "stage1": "계좌번호는 DB 신고 없음 → 신종 수법 가능성",
    "stage2": "A-1 유형 매칭 (키워드 3개) → 전형적 패턴",
    "history": "대화 이력 없음 (초면) → 금감원 통계 92% 사칭",
    "similar_cases": "최근 7일 내 3건 유사 사례 → 유행 중",
    "final_reasoning": "...",
    "recommended_action": {
      "do": ["기존 번호로 전화 확인", "경찰청 112 신고"],
      "dont": ["확인 전 송금 금지", "링크 접근 금지"]
    }
  }
}
```

**학술적 근거**:
- LLM-as-Judge: Zheng et al. (2023), "Judging LLM-as-a-Judge"
- RAG: Lewis et al. (2020), "Retrieval-Augmented Generation"

---

## 5. 설명 생성 (XAI)

### 5.1 사용자 화면 출력 예시

```json
{
  "alert": {
    "level": "DANGEROUS",
    "title": "⚠️ 위험한 메시지로 판단됩니다",
    "summary": "가족 사칭 스미싱으로 의심됩니다 (금감원 통계 33.7%)"
  },

  "detailed_explanation": {
    "step1": {
      "icon": "1️⃣",
      "title": "블랙리스트 조회",
      "result": "계좌번호 110-xxx-xxx는 신고 이력 없음",
      "interpretation": "신종 수법일 가능성 높음 (DB에 아직 등록 안됨)"
    },
    "step2": {
      "icon": "2️⃣",
      "title": "패턴 분석 (9개 유형)",
      "result": "A-1 (가족 사칭) 카테고리 매칭",
      "matched_keywords": ["엄마", "폰 고장", "급해"],
      "government_source": "금감원 2023: 가족사칭 33.7%",
      "interpretation": "전형적인 가족 사칭 패턴 (3개 핵심 키워드)"
    },
    "step3": {
      "icon": "3️⃣",
      "title": "대화 이력 분석",
      "result": "대화 이력 없음 (초면)",
      "government_source": "금감원 2023: 초면 사칭 92%",
      "interpretation": "초면 발신자 → 고위험 (통계적 근거)"
    },
    "step4": {
      "icon": "4️⃣",
      "title": "유사 사례 검색",
      "result": "최근 7일 내 동일 패턴 3건 발견",
      "cases": [
        "2024-12-08: '엄마 폰 고장' + 계좌 → 확인된 사기",
        "2024-12-06: '아빠 급해' + 송금 → 확인된 사기",
        "2024-12-03: '언니 번호 바뀜' → 확인된 사기"
      ],
      "interpretation": "최근 급증하는 수법과 일치"
    }
  },

  "final_reasoning": "
    종합 판단 (Kanana LLM):

    1. 정부 통계 근거:
       • 금감원 2023: 가족 사칭 33.7%, 초면 사칭 92%

    2. 패턴 분석:
       • A-1 유형 3개 키워드 매칭 → 전형적 패턴

    3. 대화 이력:
       • 초면 (대화 이력 0일) → 금감원 통계상 고위험

    4. 유사 사례:
       • 최근 7일 내 3건 → 현재 유행 중인 수법

    → 최종 판정: DANGEROUS (위험도 85%)
  ",

  "recommended_action": {
    "do": [
      "✅ 기존 전화번호로 직접 통화 확인",
      "✅ 가족에게 직접 확인 (메시지 아닌 통화)",
      "✅ 의심되면 경찰청 112 또는 금감원 1332 신고"
    ],
    "dont": [
      "❌ 확인 전 송금 절대 금지",
      "❌ 메시지의 계좌/링크 접근 금지",
      "❌ 개인정보 제공 금지"
    ]
  },

  "evidence_chain": [
    {
      "stage": 1,
      "method": "Rule-based (DB 조회)",
      "result": "신고 이력 없음",
      "confidence": "N/A"
    },
    {
      "stage": 2,
      "method": "Pattern Matching (9개 유형)",
      "result": "A-1 카테고리 매칭",
      "confidence": 0.82
    },
    {
      "stage": 3,
      "method": "Kanana LLM (맥락 분석)",
      "result": "DANGEROUS",
      "confidence": 0.85
    }
  ]
}
```

### 5.2 설명 생성 원칙

1. **단계별 투명성**: 각 Stage의 판단 근거 명시
2. **정부 통계 인용**: 금감원/KISA/경찰청 통계 근거 제시
3. **유사 사례 제시**: 최근 실제 사례와 비교
4. **행동 권장**: 구체적 DO/DON'T 제시

**학술적 근거**: DARPA XAI Initiative (Gunning, 2017)

---

## 6. 실제 동작 예제

### 6.1 시나리오 1: A-1 (가족 사칭) + 신종 수법

**입력**:

```
메시지: "엄마 폰 액정 깨져서 번호 바뀌었어 010-1234-5678
        급하게 돈 필요한데 110-123-456789로 30만원 보내줘"

발신자: 010-1234-5678 (미등록)
대화 이력: 없음
```

**Stage 1 처리**:

```json
{
  "stage": 1,
  "entities": {
    "accounts": ["110-123-456789"],
    "phones": ["010-1234-5678"]
  },
  "db_check": {
    "110-123-456789": {"found": false},
    "010-1234-5678": {"found": false}
  },
  "decision": null,
  "continue": true
}
```

**Stage 2 처리**:

```json
{
  "stage": 2,
  "category": "A-1",
  "matched_keywords": ["엄마", "폰", "액정", "급하게", "번호 바뀜"],
  "government_source": "금감원 2023: 가족사칭 33.7%",
  "score": 0.82,
  "continue": true
}
```

**Stage 3 처리** (Kanana LLM):

```json
{
  "stage": 3,
  "final_risk": "DANGEROUS",
  "confidence": 0.85,
  "explanation": {
    "summary": "가족 사칭 스미싱 의심 (금감원 33.7%, 초면 92%)",
    "stage1": "DB 신고 없음 → 신종 수법 또는 아직 미신고",
    "stage2": "A-1 유형 5개 키워드 매칭 → 전형적 가족 사칭",
    "history": "대화 이력 0일 → 금감원 통계상 초면 사칭 92%",
    "similar_cases": "최근 7일 내 동일 패턴 3건 → 현재 유행 중",
    "final_reasoning": "
      정부 통계 + 패턴 일치 + 초면 + 유사 사례
      → 가족 사칭 스미싱 가능성 매우 높음
    "
  }
}
```

**사용자 화면**:

```
⚠️ 위험한 메시지로 판단됩니다

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
가족 사칭 스미싱으로 의심됩니다
금감원 통계: 가족사칭 33.7%, 초면 사칭 92%
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

📋 상세 분석

1️⃣ 블랙리스트 조회
   계좌번호는 신고 이력 없음
   → 신종 수법일 가능성

2️⃣ 패턴 분석 (9개 유형)
   A-1 (가족 사칭) 매칭
   키워드: 엄마, 폰, 액정, 급하게, 번호 바뀜
   → 전형적인 가족 사칭 패턴

3️⃣ 대화 이력
   초면 (대화 이력 없음)
   → 금감원 통계: 초면 사칭 92%

4️⃣ 유사 사례
   최근 7일 내 3건 발견
   → 현재 유행 중인 수법

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
✅ 권장 행동
• 기존 전화번호로 직접 통화 확인
• 가족에게 직접 확인 (메시지 X)
• 의심되면 경찰청 112 신고

❌ 절대 금지
• 확인 전 송금 절대 금지
• 계좌/링크 접근 금지
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
```

---

### 6.2 시나리오 2: Stage 1 종료 (DB HIT)

**입력**:

```
메시지: "택배 주소 확인 bit.ly/abc123"
```

**Stage 1 처리**:

```json
{
  "stage": 1,
  "entities": {
    "urls": ["bit.ly/abc123"]
  },
  "db_check": {
    "bit.ly/abc123": {
      "found": true,
      "report_count": 1247,
      "source": "금융감독원",
      "last_reported": "2024-12-09"
    }
  },
  "decision": "CRITICAL",
  "terminate": true
}
```

**사용자 화면** (즉시 표시, 10ms):

```
🚨 위험! 즉시 차단하세요

━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
이 링크는 1,247건 신고된 악성 링크입니다
출처: 금융감독원
최근 신고: 2024-12-09
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

❌ 절대 링크를 클릭하지 마세요
✅ 즉시 대화방 나가기
✅ 경찰청 112 신고 권장
```

---

### 6.3 시나리오 3: Stage 2 종료 (NORMAL)

**입력**:

```
메시지: "오늘 저녁 7시에 강남역에서 만나자"
```

**Stage 1 처리**:

```json
{
  "stage": 1,
  "entities": {},
  "continue": true
}
```

**Stage 2 처리**:

```json
{
  "stage": 2,
  "category": "NORMAL",
  "decision": "SAFE",
  "terminate": true
}
```

**사용자 화면** (표시 안함, 백그라운드 처리)

---

## 7. 성능 및 평가

### 7.1 성능 목표

| 지표 | 목표 | 측정 방법 |
|------|------|----------|
| **응답 속도** | <100ms (평균 53ms) | Stage별 측정 |
| **Precision** | >0.85 | TP / (TP + FP) |
| **Recall** | >0.85 | TP / (TP + FN) |
| **F1-Score** | >0.85 | 2 × P × R / (P + R) |
| **설명 이해도** | >90% | 사용자 설문 |

### 7.2 Stage별 성능 분석

| Stage | 처리 비율 | 평균 시간 | 목표 정확도 |
|-------|----------|----------|------------|
| Stage 1 | 5% | <10ms | 100% (DB 팩트) |
| Stage 2 | 85% | <50ms | >80% (패턴 매칭) |
| Stage 3 | 10% | <100ms | >90% (LLM 판단) |

**전체 평균 응답 시간**: 5% × 10 + 85% × 50 + 10% × 100 = **53ms**

### 7.3 검증 계획

**Phase 1: 데이터 수집 (2주)**
- 실제 수집 스미싱 사례 1000+건
- 금감원/KISA 공개 데이터
- 레이블링 (9개 유형 + NORMAL)

**Phase 2: 성능 측정 (1주)**
- Precision, Recall, F1-Score
- 응답 속도 측정
- Stage별 정확도 측정

**Phase 3: 최적화 (1주)**
- 키워드 DB 보완 (TF-IDF)
- Kanana LLM 프롬프트 튜닝
- 임계값 조정

---

## 8. 경쟁 평가 기준 충족

### 8.1 기술 혁신성

✅ **Simple 3-Stage Pipeline**
- Rule → Pattern → LLM 단순 명확 구조
- 복잡한 Bayesian 제거, 근거 명확화

✅ **정부 통계 기반 9개 유형**
- 금감원/KISA/경찰청 공식 통계 활용

✅ **설명 가능 AI (XAI)**
- 단계별 판단 근거 투명 제시

✅ **RAG 기반 유사 사례 검색**
- 최근 30일 사례로 실시간 대응

### 8.2 실용성

✅ **빠른 응답 속도**: 평균 53ms (<100ms)

✅ **높은 정확도**: F1-Score >0.85

✅ **사용자 이해도**: 단계별 설명으로 >90%

✅ **온프레미스 가능**: Kanana LLM (보안)

### 8.3 안전성

✅ **보수적 판단**: 불확실성 높으면 SUSPICIOUS

✅ **DB 우선**: 신고 이력 = 즉시 CRITICAL

✅ **정부 통계 근거**: 모든 판단에 공식 출처

---

## 9. 학술적 근거

### 9.1 학술 논문

| 번호 | 문헌 | 적용 |
|------|------|------|
| 1 | Buchanan & Shortliffe (1984) | Rule-based Expert System |
| 2 | Luhn (1958) | Keyword Matching |
| 3 | Sparck Jones (1972) | TF-IDF (향후 적용) |
| 4 | Lewis et al. (2020) | RAG (유사 사례 검색) |
| 5 | Zheng et al. (2023) | LLM-as-Judge |
| 6 | Gunning (2017) | DARPA XAI |
| 7 | Cialdini (2006) | 설득 심리학 (영감) |

### 9.2 정부 통계

| 기관 | 연도 | 내용 |
|------|------|------|
| 금융감독원 | 2023 | 가족사칭 33.7%, 대출 35.2%, 초면 92% |
| KISA | 2024 | 택배 65%, 청첩장 1.7만건 |
| 경찰청 | 2022-23 | 기관사칭 78%, 공공 19.7배↑ |
| 국가수사본부 | 2024 | 투자 리딩방 5,340억 |

---

## 10. 구현 로드맵

### Phase 1: 기반 구축 (2주)

**Week 1**:
- Kanana LLM 온프레미스 설치
- DB 연동 (금융감독원, 경찰청, 민간)
- 엔티티 추출 정규식 구현

**Week 2**:
- 9개 유형 키워드 DB 구축
- Stage 1/2 구현
- Stage 3 Kanana 프롬프트 작성

### Phase 2: 통합 및 테스트 (2주)

**Week 3**:
- 3-Stage Pipeline 통합
- RAG 유사 사례 검색 구현
- 설명 생성 로직 구현

**Week 4**:
- 1000+ 샘플 테스트
- Precision/Recall/F1 측정
- 응답 속도 최적화

### Phase 3: 최적화 (1주)

**Week 5**:
- 키워드 DB 보완 (TF-IDF)
- Kanana 프롬프트 튜닝
- 사용자 설명 이해도 테스트

### Phase 4: 배포 (1주)

**Week 6**:
- 성능 최종 검증
- 카카오톡 통합
- 사용자 파일럿 테스트

---

## 11. 참고 문헌

### 학술 논문

1. Buchanan, B. G., & Shortliffe, E. H. (1984). Rule-Based Expert Systems: The MYCIN Experiments
2. Luhn, H. P. (1958). A Statistical Approach to Mechanized Encoding and Searching
3. Sparck Jones, K. (1972). A Statistical Interpretation of Term Specificity
4. Lewis, P., et al. (2020). Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks
5. Zheng, L., et al. (2023). Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena
6. Gunning, D. (2017). Explainable Artificial Intelligence (XAI). DARPA
7. Cialdini, R. B. (2006). Influence: The Psychology of Persuasion

### 정부 통계 및 보도자료

1. 금융감독원 (2023). 보이스피싱 피해 현황 및 예방 대책
2. 한국인터넷진흥원 (2024). 2024년 2분기 스미싱 공격 분석 보고서
3. 경찰청 (2022). 사이버범죄 통계 - 기관 사칭
4. 경찰청 (2023). 전기통신금융사기 유형별 통계
5. 국가수사본부 (2024). 투자 리딩방 특별단속 결과

---

**END OF DOCUMENT**
