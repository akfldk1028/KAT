# Agent B (ì•ˆì‹¬ ê°€ë“œ) - ê°œë°œììš© ê¸°ëŠ¥ëª…ì„¸ì„œ v2.0

**ì‘ì„±ì¼**: 2025-12-09
**ëŒ€ìƒ**: Backend/AI ê°œë°œì
**ëª©ì **: Agent B êµ¬í˜„ì„ ìœ„í•œ ìƒì„¸ ê¸°ìˆ  ëª…ì„¸ì„œ
**ë¬¸ì„œ íƒ€ì…**: ê¸°ëŠ¥ëª…ì„¸ì„œ (Functional Specification)

---

## ğŸ“‹ ëª©ì°¨

1. [ì‹œìŠ¤í…œ ê°œìš”](#1-ì‹œìŠ¤í…œ-ê°œìš”)
2. [ê¸°ìˆ  ì•„í‚¤í…ì²˜](#2-ê¸°ìˆ -ì•„í‚¤í…ì²˜)
3. [ë°ì´í„° ëª¨ë¸](#3-ë°ì´í„°-ëª¨ë¸)
4. [API ëª…ì„¸](#4-api-ëª…ì„¸)
5. [MCP ë„êµ¬ ëª…ì„¸](#5-mcp-ë„êµ¬-ëª…ì„¸)
6. [í•µì‹¬ ì•Œê³ ë¦¬ì¦˜](#6-í•µì‹¬-ì•Œê³ ë¦¬ì¦˜)
7. [êµ¬í˜„ ìš°ì„ ìˆœìœ„](#7-êµ¬í˜„-ìš°ì„ ìˆœìœ„)
8. [í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­](#8-í…ŒìŠ¤íŠ¸-ìš”êµ¬ì‚¬í•­)
9. [ë°°í¬ ë° ì„±ëŠ¥ ëª©í‘œ](#9-ë°°í¬-ë°-ì„±ëŠ¥-ëª©í‘œ)

---

## 1. ì‹œìŠ¤í…œ ê°œìš”

### 1.1 ì‹œìŠ¤í…œ ì •ì˜

**Agent B (ì•ˆì‹¬ ê°€ë“œ)**ëŠ” ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ í”¼ì‹± ì‚¬ê¸°ë¥¼ íƒì§€í•˜ê³  ì‚¬ìš©ìë¥¼ ë³´í˜¸í•˜ëŠ” AI ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ì—ì´ì „íŠ¸ì…ë‹ˆë‹¤.

**í•µì‹¬ íŠ¹ì§•**:
- **AI-driven Architecture**: AIê°€ ì£¼ë„í•˜ê³  Ruleì„ ë„êµ¬ë¡œ ì‚¬ìš©
- **ReAct Loop**: Thought â†’ Action â†’ Observation ë°˜ë³µ (ìµœëŒ€ 5 ì‚¬ì´í´)
- **Bayesian ìµœì¢… íŒë‹¨**: P(Fraud|Evidence) ì‚¬í›„ í™•ë¥  ê³„ì‚°
- **XAI ì„¤ëª…**: decision_processë¡œ ì¶”ë¡  ê³¼ì • íˆ¬ëª…í™”

### 1.2 ì‹œìŠ¤í…œ ì»¨í…ìŠ¤íŠ¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ KakaoTalk User  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ë©”ì‹œì§€ ì „ì†¡
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Agent B (Hybrid Agent)          â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   KananaAgent (Brain)        â”‚  â”‚
â”‚  â”‚   - ReAct Loop Engine        â”‚  â”‚
â”‚  â”‚   - System Prompt            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚             â”‚                       â”‚
â”‚             â†“                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   MCP Tools (6ê°œ)            â”‚  â”‚
â”‚  â”‚   1. context_analyzer        â”‚  â”‚
â”‚  â”‚   2. threat_intelligence     â”‚  â”‚
â”‚  â”‚   3. social_graph            â”‚  â”‚
â”‚  â”‚   4. entity_extractor        â”‚  â”‚
â”‚  â”‚   5. bayesian_calculator     â”‚  â”‚
â”‚  â”‚   6. scam_case_rag           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â†“ ë¶„ì„ ê²°ê³¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend UI   â”‚
â”‚   - Risk Alert  â”‚
â”‚   - Explanation â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.3 ê¸°ìˆ  ìŠ¤íƒ

| ë ˆì´ì–´ | ê¸°ìˆ  | ë²„ì „ | ìš©ë„ |
|--------|------|------|------|
| **AI Model** | Kanana (Kakao) | v1.0 | ReAct Loop Brain |
| **Framework** | FastMCP | v0.7+ | MCP ë„êµ¬ êµ¬í˜„ |
| **Backend** | FastAPI | 0.115+ | REST API ì„œë²„ |
| **Database** | PostgreSQL | 15+ | ì‹ ê³  DB, ëŒ€í™” ì´ë ¥ |
| **Cache** | Redis | 7+ | ì‹¤ì‹œê°„ ì„¸ì…˜ ê´€ë¦¬ |
| **Language** | Python | 3.11+ | ì „ì²´ ì‹œìŠ¤í…œ |

---

## 2. ê¸°ìˆ  ì•„í‚¤í…ì²˜

### 2.1 ì‹œìŠ¤í…œ êµ¬ì¡°

```
agent-b/
â”œâ”€ agent/
â”‚  â”œâ”€ core/
â”‚  â”‚  â”œâ”€ kanana_agent.py         # ReAct Loop ì—”ì§„ (250ì¤„)
â”‚  â”‚  â”œâ”€ system_prompt.py        # System Prompt ê´€ë¦¬
â”‚  â”‚  â””â”€ config.py               # ì„¤ì • ê´€ë¦¬
â”‚  â”œâ”€ mcp_tools/
â”‚  â”‚  â”œâ”€ context_analyzer.py     # MCP 1: íŒ¨í„´ ë¶„ë¥˜
â”‚  â”‚  â”œâ”€ threat_intelligence.py  # MCP 2: DB ì¡°íšŒ
â”‚  â”‚  â”œâ”€ social_graph.py         # MCP 3: ì‹ ë¢°ë„ ê³„ì‚°
â”‚  â”‚  â”œâ”€ entity_extractor.py     # MCP 4: ì—”í‹°í‹° ì¶”ì¶œ
â”‚  â”‚  â”œâ”€ bayesian_calculator.py  # MCP 5: í™•ë¥  ê³„ì‚°
â”‚  â”‚  â””â”€ scam_case_rag.py        # MCP 6: ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰
â”‚  â””â”€ utils/
â”‚     â”œâ”€ logger.py               # ë¡œê¹… ìœ í‹¸
â”‚     â””â”€ validators.py           # ì…ë ¥ ê²€ì¦
â”œâ”€ api/
â”‚  â”œâ”€ server.py                  # FastAPI ì„œë²„
â”‚  â”œâ”€ routers/
â”‚  â”‚  â””â”€ analysis.py             # /analyze ì—”ë“œí¬ì¸íŠ¸
â”‚  â””â”€ schemas.py                 # Pydantic ëª¨ë¸
â”œâ”€ database/
â”‚  â”œâ”€ models.py                  # SQLAlchemy ëª¨ë¸
â”‚  â”œâ”€ migrations/                # Alembic ë§ˆì´ê·¸ë ˆì´ì…˜
â”‚  â””â”€ seed_data/                 # ì´ˆê¸° ë°ì´í„°
â”œâ”€ tests/
â”‚  â”œâ”€ unit/                      # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
â”‚  â”œâ”€ integration/               # í†µí•© í…ŒìŠ¤íŠ¸
â”‚  â””â”€ e2e/                       # E2E í…ŒìŠ¤íŠ¸
â”œâ”€ config/
â”‚  â”œâ”€ development.yaml           # ê°œë°œ í™˜ê²½ ì„¤ì •
â”‚  â””â”€ production.yaml            # ìš´ì˜ í™˜ê²½ ì„¤ì •
â”œâ”€ docker/
â”‚  â”œâ”€ Dockerfile
â”‚  â””â”€ docker-compose.yml
â””â”€ requirements.txt
```

### 2.2 ReAct Loop ì²˜ë¦¬ íë¦„

```python
# Pseudocode: KananaAgent.analyze()
def analyze(message: str, context: Dict) -> Dict:
    """
    ReAct Loop ì‹¤í–‰ (ìµœëŒ€ 5 ì‚¬ì´í´)
    """
    observations = []

    for cycle in range(1, 6):
        # Step 1: Thought (ì‚¬ê³ )
        thought = kanana_llm.think(
            message=message,
            context=context,
            previous_observations=observations
        )

        # ì¢…ë£Œ ì¡°ê±´ í™•ì¸
        if thought.action == "FINAL_ANSWER":
            break

        # Step 2: Action (í–‰ë™) - ë„êµ¬ ì„ íƒ
        action = thought.action  # e.g., "context_analyzer_mcp"

        # Step 3: Observation (ê´€ì°°) - ë„êµ¬ ì‹¤í–‰
        observation = mcp_tools[action].execute(
            message=message,
            context=context
        )
        observations.append(observation)

    # Step 4: Bayesian ìµœì¢… íŒë‹¨
    final_result = bayesian_calculator.calculate_posterior(
        pattern_confidence=observations['context_analyzer']['confidence'],
        db_prior=observations['threat_intelligence']['db_prior'],
        trust_score=observations['social_graph']['trust_score']
    )

    return {
        "risk_level": final_result.risk_level,
        "confidence": final_result.confidence,
        "decision_process": observations,
        "recommendations": generate_recommendations(final_result)
    }
```

### 2.3 ë°ì´í„° íë¦„ë„

```
[User] â†’ [KakaoTalk] â†’ [API Gateway] â†’ [KananaAgent]
                                            â”‚
                                            â†“
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   ReAct Loop (ìµœëŒ€ 5íšŒ)     â”‚
                          â”‚                             â”‚
                          â”‚  Cycle 1: Thought â†’ Action  â”‚
                          â”‚  â”œâ”€ context_analyzer âœ“      â”‚
                          â”‚  â””â”€ Observation ì €ì¥        â”‚
                          â”‚                             â”‚
                          â”‚  Cycle 2: Thought â†’ Action  â”‚
                          â”‚  â”œâ”€ threat_intelligence âœ“   â”‚
                          â”‚  â””â”€ Observation ì €ì¥        â”‚
                          â”‚                             â”‚
                          â”‚  Cycle 3: FINAL_ANSWER      â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â†“
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  Bayesian Calculator        â”‚
                          â”‚  P(Fraud|Evidence)          â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                            â”‚
                                            â†“
[Response] â† [Frontend] â† [API] â† [ê²°ê³¼ + XAI ì„¤ëª…]
```

---

## 3. ë°ì´í„° ëª¨ë¸

### 3.1 ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ

#### 3.1.1 `reported_numbers` í…Œì´ë¸”

```sql
CREATE TABLE reported_numbers (
    id SERIAL PRIMARY KEY,
    phone_number VARCHAR(20) NOT NULL UNIQUE,
    report_count INTEGER DEFAULT 1,
    first_reported_at TIMESTAMP NOT NULL,
    last_reported_at TIMESTAMP NOT NULL,
    scam_types JSONB,  -- ["A-1", "B-2"] í˜•íƒœ
    metadata JSONB,    -- ì¶”ê°€ ì •ë³´
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_phone_number ON reported_numbers(phone_number);
CREATE INDEX idx_last_reported ON reported_numbers(last_reported_at DESC);
```

**ì˜ˆì‹œ ë°ì´í„°**:
```json
{
    "id": 1,
    "phone_number": "010-1234-5678",
    "report_count": 127,
    "first_reported_at": "2024-01-15T10:00:00Z",
    "last_reported_at": "2024-11-20T15:30:00Z",
    "scam_types": ["A-1", "A-2"],
    "metadata": {
        "source": "KISA",
        "severity": "HIGH"
    }
}
```

#### 3.1.2 `conversation_history` í…Œì´ë¸”

```sql
CREATE TABLE conversation_history (
    id SERIAL PRIMARY KEY,
    user_id VARCHAR(50) NOT NULL,
    contact_phone VARCHAR(20) NOT NULL,
    contact_name VARCHAR(100),
    message_count INTEGER DEFAULT 0,
    first_message_at TIMESTAMP NOT NULL,
    last_message_at TIMESTAMP NOT NULL,
    tone_consistency FLOAT,  -- 0.0~1.0
    phone_change_detected BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ì¸ë±ìŠ¤
CREATE INDEX idx_user_contact ON conversation_history(user_id, contact_phone);
CREATE INDEX idx_last_message ON conversation_history(last_message_at DESC);
```

**ì˜ˆì‹œ ë°ì´í„°**:
```json
{
    "id": 1,
    "user_id": "user_123",
    "contact_phone": "010-9876-5432",
    "contact_name": "ì—„ë§ˆ",
    "message_count": 45,
    "first_message_at": "2024-11-01T09:00:00Z",
    "last_message_at": "2024-11-25T18:30:00Z",
    "tone_consistency": 0.95,
    "phone_change_detected": false
}
```

#### 3.1.3 `scam_cases` í…Œì´ë¸”

```sql
CREATE TABLE scam_cases (
    id SERIAL PRIMARY KEY,
    category VARCHAR(10) NOT NULL,  -- "A-1", "B-2" ë“±
    message_pattern TEXT NOT NULL,
    embedding VECTOR(768),  -- Text embedding for RAG
    cialdini_principles JSONB,  -- ["Urgency", "Authority"]
    created_at TIMESTAMP DEFAULT NOW()
);

-- ë²¡í„° ê²€ìƒ‰ ì¸ë±ìŠ¤ (pgvector)
CREATE INDEX idx_scam_embedding ON scam_cases
USING ivfflat (embedding vector_cosine_ops);
```

### 3.2 API Request/Response ëª¨ë¸

#### 3.2.1 `/analyze` ì—”ë“œí¬ì¸íŠ¸

**Request**:
```python
class AnalyzeRequest(BaseModel):
    user_id: str
    message: str
    sender_phone: str
    sender_name: Optional[str] = None
    conversation_context: Optional[List[Dict]] = None  # ìµœê·¼ 10ê°œ ë©”ì‹œì§€

    class Config:
        json_schema_extra = {
            "example": {
                "user_id": "user_123",
                "message": "ì—„ë§ˆ, ë‚˜ í° ê³ ì¥ë‚˜ì„œ ë²ˆí˜¸ ë°”ë€Œì—ˆì–´ 010-1234-5678",
                "sender_phone": "010-1234-5678",
                "sender_name": "ì—„ë§ˆ",
                "conversation_context": [
                    {
                        "role": "sender",
                        "content": "ì˜¤ëŠ˜ ì €ë… ë­ ë¨¹ì„ë˜?",
                        "timestamp": "2024-11-25T18:00:00Z"
                    }
                ]
            }
        }
```

**Response**:
```python
class AnalyzeResponse(BaseModel):
    risk_level: Literal["CRITICAL", "HIGH", "MEDIUM", "LOW", "SAFE"]
    confidence: float  # 0.0 ~ 1.0
    category: Optional[str]  # "A-1", "B-2" ë“±
    cialdini_principles: List[str]  # ["Urgency", "Liking"]
    decision_process: List[Dict]  # ReAct Loop ì¶”ë¡  ê³¼ì •
    recommendations: List[str]
    bayesian_result: Dict
    processing_time_ms: int

    class Config:
        json_schema_extra = {
            "example": {
                "risk_level": "CRITICAL",
                "confidence": 0.92,
                "category": "A-1",
                "cialdini_principles": ["Urgency", "Liking"],
                "decision_process": [
                    {
                        "cycle": 1,
                        "thought": "ê°€ì¡± í˜¸ì¹­ + ê¸´ê¸‰ì„± íŒ¨í„´ ì˜ì‹¬",
                        "action": "context_analyzer_mcp",
                        "observation": {
                            "category": "A-1",
                            "confidence": 0.92
                        }
                    }
                ],
                "recommendations": [
                    "ì ˆëŒ€ ì†¡ê¸ˆí•˜ì§€ ë§ˆì„¸ìš”",
                    "ê¸°ì¡´ ë²ˆí˜¸ë¡œ ì§ì ‘ ì „í™” í™•ì¸í•˜ì„¸ìš”"
                ],
                "bayesian_result": {
                    "prior": 0.85,
                    "posterior": 0.92,
                    "evidence_weights": {
                        "pattern": 0.4,
                        "db": 0.3,
                        "trust": 0.3
                    }
                },
                "processing_time_ms": 150
            }
        }
```

---

## 4. API ëª…ì„¸

### 4.1 RESTful API ì—”ë“œí¬ì¸íŠ¸

#### 4.1.1 `POST /api/v1/analyze`

**ìš©ë„**: ë©”ì‹œì§€ ìœ„í—˜ë„ ë¶„ì„

**Headers**:
```
Content-Type: application/json
Authorization: Bearer {access_token}
```

**Request Body**: `AnalyzeRequest` (ìœ„ ì°¸ì¡°)

**Response**:
- **200 OK**: `AnalyzeResponse` (ìœ„ ì°¸ì¡°)
- **400 Bad Request**: ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨
- **500 Internal Server Error**: ì„œë²„ ì˜¤ë¥˜

**ì„±ëŠ¥ ìš”êµ¬ì‚¬í•­**:
- **ì •ìƒ ë©”ì‹œì§€**: <80ms (1 ì‚¬ì´í´)
- **í”¼ì‹± ë©”ì‹œì§€**: <150ms (í‰ê·  2.8 ì‚¬ì´í´)
- **ë³µì¡í•œ ì¼€ì´ìŠ¤**: <300ms (5 ì‚¬ì´í´)

#### 4.1.2 `POST /api/v1/feedback`

**ìš©ë„**: ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

**Request**:
```json
{
    "analysis_id": "uuid-123",
    "user_feedback": "correct" | "incorrect",
    "user_comment": "ì‹¤ì œë¡œ ê°€ì¡±ì´ ë§ìŠµë‹ˆë‹¤"
}
```

**Response**:
```json
{
    "status": "success",
    "message": "í”¼ë“œë°±ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤"
}
```

---

## 5. MCP ë„êµ¬ ëª…ì„¸

### 5.1 context_analyzer_mcp

**ëª©ì **: ë©”ì‹œì§€ íŒ¨í„´ ë¶„ë¥˜ (A-1 ~ C-3 ì¤‘ í•˜ë‚˜)

**Input**:
```python
{
    "message": str,
    "context": {
        "sender_name": Optional[str],
        "previous_messages": Optional[List[str]]
    }
}
```

**Output**:
```python
{
    "category": str,  # "A-1", "B-2" ë“±
    "confidence": float,  # 0.0 ~ 1.0
    "cialdini_principles": List[str],  # ["Urgency", "Liking"]
    "patterns_detected": List[str],  # ["ê°€ì¡± í˜¸ì¹­", "ê¸´ê¸‰ì„± í‚¤ì›Œë“œ"]
    "reasoning": str  # "ê°€ì¡± í˜¸ì¹­('ì—„ë§ˆ') + ê¸´ê¸‰ì„±('í° ê³ ì¥') ê°ì§€"
}
```

**êµ¬í˜„ ìš”êµ¬ì‚¬í•­**:
- ê¸ˆê°ì› 2ëŒ€ë¶„ë¥˜ (ì‚¬ì¹­í˜• vs ì‚¬ê¸°í˜•) ê¸°ë°˜ 9ê°œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
- Cialdini 6 Principles ìë™ ë§¤í•‘
- í•œêµ­ì–´ NLP ì²˜ë¦¬ (í˜•íƒœì†Œ ë¶„ì„, ê°œì²´ëª… ì¸ì‹)

**ì¹´í…Œê³ ë¦¬ ì •ì˜**:

```python
# ëŒ€ë¶„ë¥˜ 1: ì‚¬ì¹­í˜• (Impersonation)
CATEGORIES = {
    # Aê·¸ë£¹: ê°œì¸ ê´€ê³„ ì‚¬ì¹­
    "A-1": {
        "name": "ì§€ì¸ ë° ê°€ì¡± ì‚¬ì¹­",
        "patterns": ["ì—„ë§ˆ", "ì•„ë¹ ", "ì•„ë“¤", "ë”¸", "ì•¡ì • íŒŒì†", "ê¸‰ì „"],
        "cialdini": ["Liking", "Urgency"]
    },
    "A-2": {
        "name": "ê²½ì¡°ì‚¬ ë¹™ì",
        "patterns": ["ì²­ì²©ì¥", "ë¶€ê³ ì¥", "ëª¨ë°”ì¼ ì²­ì²©ì¥"],
        "cialdini": ["Social Proof"]
    },
    "A-3": {
        "name": "ë¡œë§¨ìŠ¤ ìŠ¤ìº ",
        "patterns": ["ì‚¬ê·€", "ë§Œë‚˜", "ë°ì´íŠ¸", "ì†¡ê¸ˆ"],
        "cialdini": ["Liking", "Reciprocity"]
    },

    # Bê·¸ë£¹: ê¸°ê´€/ì œë„ ì‚¬ì¹­
    "B-1": {
        "name": "ìˆ˜ì‚¬ ë° ê¸ˆìœµ ê¸°ê´€ ì‚¬ì¹­",
        "patterns": ["ê²€ì°°", "ê¸ˆê°ì›", "ê²½ì°°", "ê³„ì¢Œ ë™ê²°"],
        "cialdini": ["Authority", "Fear"]
    },
    "B-2": {
        "name": "ê³µê³µ í–‰ì • ì•Œë¦¼ ì‚¬ì¹­",
        "patterns": ["ê±´ê°•ê²€ì§„", "êµí†µë²”ì¹™ê¸ˆ", "ë¯¸ë‚©"],
        "cialdini": ["Authority"]
    },
    "B-3": {
        "name": "íƒë°° ë° ë¬¼ë¥˜ ì‚¬ì¹­",
        "patterns": ["ë°°ì†¡", "íƒë°°", "ì£¼ì†Œ ë¶ˆëª…"],
        "cialdini": ["Social Proof"]
    },

    # ëŒ€ë¶„ë¥˜ 2: ì‚¬ê¸°í˜• (Fraud)
    # Cê·¸ë£¹: ê²½ì œ ìœ ì¸/í˜‘ë°•
    "C-1": {
        "name": "ëŒ€ì¶œ ë¹™ì",
        "patterns": ["ì €ê¸ˆë¦¬", "ëŒ€í™˜", "ì •ë¶€ì§€ì›ê¸ˆ"],
        "cialdini": ["Scarcity", "Reciprocity"]
    },
    "C-2": {
        "name": "íˆ¬ì ë¦¬ë”©ë°©",
        "patterns": ["ì½”ì¸", "ì£¼ì‹", "ìˆ˜ìµë¥ ", "ë¦¬ë”©ë°©"],
        "cialdini": ["Scarcity", "Social Proof"]
    },
    "C-3": {
        "name": "ëª¸ìº  í”¼ì‹±",
        "patterns": ["ì˜ìƒí†µí™”", "ë…¹í™”", "ìœ í¬", "í˜‘ë°•"],
        "cialdini": ["Fear", "Liking"]
    }
}
```

### 5.2 threat_intelligence_mcp

**ëª©ì **: ë‹¤ì¤‘ ì†ŒìŠ¤ DB ì¡°íšŒ ë° í†µí•© ìœ„í˜‘ ì¸í…”ë¦¬ì „ìŠ¤ ë¶„ì„

**êµ¬í˜„ëœ DB ì†ŒìŠ¤** (6ê°œ):

| DB ì†ŒìŠ¤ | ì¡°íšŒ ëŒ€ìƒ | êµ¬í˜„ íŒŒì¼ | API ë¬¸ì„œ |
|---------|----------|----------|---------|
| **1. TheCheat API** | ì „í™”ë²ˆí˜¸, ê³„ì¢Œë²ˆí˜¸ | `agent/core/thecheat_api.py` | [API Docs](https://apidocs.thecheat.co.kr/docs/api-usage/api-common) |
| **2. KISA í”¼ì‹±ì‚¬ì´íŠ¸** | URL (27,582ê°œ ì‚¬ì´íŠ¸) | `agent/core/kisa_phishing_api.py` | [Open API](https://www.data.go.kr/data/15109780) |
| **3. ê²½ì°°ì²­ ì‚¬ì´ë²„ë²”ì£„** | ì „í™”ë²ˆí˜¸, ê³„ì¢Œ, ì´ë©”ì¼ | `api/fraud_mcp_server.py` | [ê²½ì°°ì²­](https://www.police.go.kr/www/security/cyber/cyber04.jsp) |
| **4. CounterScam 112** | ì „í™”ë²ˆí˜¸ | `api/fraud_mcp_server.py` | [í”¼ì‹±ì¡°íšŒ](https://www.counterscam112.go.kr/phishing/searchPhone.do) |
| **5. Google Safe Browsing** | URL ì•…ì„±ì½”ë“œ/í”¼ì‹± | `api/fraud_mcp_server.py` | [í•œêµ­íŒ API](https://lrl.kr/bbs/board.php?bo_table=docs&wr_id=27) |
| **6. VirusTotal** | URL ì•…ì„± ì—¬ë¶€ | `api/fraud_mcp_server.py` | [VirusTotal](https://docs.virustotal.com/v2.0/reference/getting-started) |

---

#### 1. TheCheat API (ì „í™”ë²ˆí˜¸/ê³„ì¢Œë²ˆí˜¸ ì¡°íšŒ)

**êµ¬í˜„ íŒŒì¼**: `testdata/KAT/agent/core/thecheat_api.py`

**ì£¼ìš” ê¸°ëŠ¥**:
```python
class TheCheatClient:
    """TheCheat ì‚¬ê¸° ì‹ ê³  DB API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("THECHEAT_API_KEY")
        self.endpoint = "https://api.thecheat.co.kr/api/v2/fraud/search"

    def search_phone(self, phone_number: str) -> Dict[str, Any]:
        """ì „í™”ë²ˆí˜¸ ì¡°íšŒ

        Returns:
            {
                "is_reported": bool,  # ì‹ ê³  ì—¬ë¶€
                "keyword": str,       # ì¡°íšŒí•œ ë²ˆí˜¸
                "reported_date": str, # ìµœì´ˆ ì‹ ê³ ì¼
                "details": str,       # ì‹ ê³  ë‚´ìš©
                "source": "TheCheat"
            }
        """
        normalized = re.sub(r'[-\s]', '', phone_number)
        response = requests.post(
            self.endpoint,
            headers={"X-TheCheat-ApiKey": self.api_key},
            json={"keyword_type": "phone", "keyword": normalized}
        )
        data = response.json()["data"]
        return {
            "is_reported": data.get("caution") == "Y",
            "keyword": data.get("keyword"),
            "reported_date": data.get("created_date"),
            "details": data.get("content"),
            "source": "TheCheat"
        }

    def search_account(self, account_number: str, bank_code: str = None) -> Dict:
        """ê³„ì¢Œë²ˆí˜¸ ì¡°íšŒ (bank_codeëŠ” ì„ íƒì )"""
        payload = {"keyword_type": "account", "keyword": account_number}
        if bank_code:
            payload["bank_code"] = bank_code
        response = requests.post(
            self.endpoint,
            headers={"X-TheCheat-ApiKey": self.api_key},
            json=payload
        )
        # ... ë™ì¼í•œ ì‘ë‹µ êµ¬ì¡°
```

**í™˜ê²½ ë³€ìˆ˜**: `THECHEAT_API_KEY` (í•„ìˆ˜)

---

#### 2. KISA í”¼ì‹±ì‚¬ì´íŠ¸ API (URL ì¡°íšŒ)

**êµ¬í˜„ íŒŒì¼**: `testdata/KAT/agent/core/kisa_phishing_api.py`

**ì£¼ìš” íŠ¹ì§•**:
- 27,582ê°œ í”¼ì‹± ì‚¬ì´íŠ¸ DB (2024-12 ê¸°ì¤€)
- ë¡œì»¬ ìºì‹œ ì‹œìŠ¤í…œ (24ì‹œê°„ TTL)
- O(1) ë„ë©”ì¸ ê²€ìƒ‰ ì„±ëŠ¥

**êµ¬í˜„ ì½”ë“œ**:
```python
class KISAPhishingClient:
    """KISA í”¼ì‹±ì‚¬ì´íŠ¸ URL Open API í´ë¼ì´ì–¸íŠ¸"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("KISA_API_KEY")
        self.endpoint = "https://api.odcloud.kr/api/15109780/v1/uddi:707478dd-938f-4155-badb-fae6202ee7ed"

    def fetch_page(self, page: int = 1, per_page: int = 1000) -> Dict:
        """í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ë°ì´í„° ì¡°íšŒ (ì´ 27,582ê°œ ë ˆì½”ë“œ)"""
        response = requests.get(
            self.endpoint,
            params={"page": page, "perPage": per_page, "serviceKey": self.api_key}
        )
        return response.json()

class KISAPhishingCache:
    """ë¡œì»¬ ìºì‹œ ì‹œìŠ¤í…œ - 24ì‹œê°„ TTL"""

    def __init__(self, cache_file: str = "kisa_phishing_cache.json"):
        self.cache_file = cache_file
        self.cache_data = self._load_or_fetch_cache()

    def is_phishing(self, url: str) -> Optional[Dict]:
        """ìºì‹œëœ DBì—ì„œ URL í”¼ì‹± ì—¬ë¶€ í™•ì¸ (O(1) ê²€ìƒ‰)"""
        domain = self._extract_domain(url)
        phishing_info = self.cache_data["domain_index"].get(domain)

        if phishing_info:
            return {
                "is_phishing": True,
                "domain": domain,
                "reported_date": phishing_info.get("ë“±ë¡ì¼ì‹œ"),
                "url_pattern": phishing_info.get("ì‚¬ì´íŠ¸ì£¼ì†Œ"),
                "source": "KISA"
            }
        return {"is_phishing": False, "source": "KISA"}

    def _extract_domain(self, url: str) -> str:
        """URLì—ì„œ ë„ë©”ì¸ ì¶”ì¶œ ë° ì •ê·œí™”"""
        parsed = urlparse(url if "//" in url else f"http://{url}")
        domain = parsed.netloc or parsed.path.split('/')[0]
        return domain.lower()
```

**í™˜ê²½ ë³€ìˆ˜**: `KISA_API_KEY` (í•„ìˆ˜)

**ì„±ëŠ¥ ìµœì í™”**:
- ì „ì²´ DBë¥¼ ë¡œì»¬ ìºì‹œ (27,582 ë ˆì½”ë“œ)
- 24ì‹œê°„ TTL ìë™ ê°±ì‹ 
- ë„ë©”ì¸ ê¸°ë°˜ O(1) í•´ì‹œ ê²€ìƒ‰

---

#### 3~6. FastMCP í†µí•© ì„œë²„ (ê²½ì°°ì²­/CounterScam/Google/VirusTotal)

**êµ¬í˜„ íŒŒì¼**: `testdata/KAT/api/fraud_mcp_server.py`

**MCP Tools**:
```python
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Fraud Check Server")

@mcp.tool()
def check_police_db(search_type: str, value: str) -> str:
    """ê²½ì°°ì²­ ì‚¬ì´ë²„ë²”ì£„ ì‹ ê³ ì‹œìŠ¤í…œ

    Args:
        search_type: "phone", "account", "email"
        value: ì¡°íšŒí•  ê°’

    Returns:
        ì‹ ê³  ì—¬ë¶€ ë° ìƒì„¸ ì •ë³´
    """
    url = "https://www.police.go.kr/user/search/ND_searchResult.do"
    type_map = {'phone': '1', 'account': '2', 'email': '3'}

    response = requests.post(
        url,
        data={'colTarget': type_map[search_type], 'searchTerm': value},
        verify=False
    )

    if "ì ‘ìˆ˜ëœ ë¯¼ì›ì´ ì—†ìŠµë‹ˆë‹¤" in response.text:
        return "Police DB: No reports found (Clean)."
    elif "ì‹ ê³ ëœ ë²ˆí˜¸ì…ë‹ˆë‹¤" in response.text:
        return "Police DB: REPORTED! Caution required."
    else:
        return "Police DB: Check required (ambiguous result)."

@mcp.tool()
def check_counterscam(phone_number: str) -> str:
    """CounterScam 112 í”¼ì‹± ì „í™”ë²ˆí˜¸ ì¡°íšŒ

    Args:
        phone_number: ì „í™”ë²ˆí˜¸ (010-1234-5678 í˜•ì‹)

    Returns:
        í”¼ì‹± ì‹ ê³  ì—¬ë¶€
    """
    url = "https://www.counterscam112.go.kr/phishing/searchPhone.do"
    response = requests.post(url, data={'phoneNumber': phone_number})

    # BeautifulSoup íŒŒì‹±
    soup = BeautifulSoup(response.content, 'html.parser')
    result = soup.find('div', class_='result')

    if result and "ì‹ ê³ ëœ ì „í™”ë²ˆí˜¸" in result.text:
        return "CounterScam: REPORTED! Phishing number detected."
    return "CounterScam: No reports found (Clean)."

@mcp.tool()
def check_google_safe_browsing(url: str) -> str:
    """Google Safe Browsing API

    Args:
        url: ì¡°íšŒí•  URL

    Returns:
        ì•…ì„±ì½”ë“œ/í”¼ì‹± ì—¬ë¶€

    Requires:
        GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜
    """
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        return "Google Safe Browsing: API key not configured."

    api_url = f"https://safebrowsing.googleapis.com/v4/threatMatches:find?key={api_key}"
    payload = {
        "client": {"clientId": "kanana-agent", "clientVersion": "1.0"},
        "threatInfo": {
            "threatTypes": ["MALWARE", "SOCIAL_ENGINEERING"],
            "platformTypes": ["ANY_PLATFORM"],
            "threatEntryTypes": ["URL"],
            "threatEntries": [{"url": url}]
        }
    }

    response = requests.post(api_url, json=payload)
    data = response.json()

    if "matches" in data:
        threats = [m["threatType"] for m in data["matches"]]
        return f"Google Safe Browsing: THREAT DETECTED! {', '.join(threats)}"
    return "Google Safe Browsing: Clean (No threats)."

@mcp.tool()
def check_virustotal(url: str) -> str:
    """VirusTotal API

    Args:
        url: ì¡°íšŒí•  URL

    Returns:
        ì•…ì„± íŒì • ì—¬ë¶€ (ì—”ì§„ë³„ ìŠ¤ìº” ê²°ê³¼)

    Requires:
        VIRUSTOTAL_API_KEY í™˜ê²½ ë³€ìˆ˜
    """
    api_key = os.getenv("VIRUSTOTAL_API_KEY")
    if not api_key:
        return "VirusTotal: API key not configured."

    api_url = "https://www.virustotal.com/vtapi/v2/url/report"
    response = requests.get(api_url, params={"apikey": api_key, "resource": url})
    data = response.json()

    if data["response_code"] == 1:
        positives = data["positives"]
        total = data["total"]
        return f"VirusTotal: {positives}/{total} engines detected this URL as malicious."
    return "VirusTotal: URL not found in database or clean."
```

**í™˜ê²½ ë³€ìˆ˜**:
- `GOOGLE_API_KEY` (Google Safe Browsing)
- `VIRUSTOTAL_API_KEY` (VirusTotal)

---

#### í†µí•© ì¡°íšŒ ë¡œì§

**Input**:
```python
{
    "identifier": str,      # ì „í™”ë²ˆí˜¸, URL, ê³„ì¢Œë²ˆí˜¸, ì´ë©”ì¼
    "identifier_type": str  # "phone", "url", "account", "email"
}
```

**Output**:
```python
{
    "has_reported": bool,
    "sources": List[str],       # ["TheCheat", "KISA", "Police"]
    "prior_probability": float, # 0.0 ~ 1.0
    "details": {
        "thecheat": Optional[Dict],
        "kisa": Optional[Dict],
        "police": Optional[str],
        "counterscam": Optional[str],
        "google": Optional[str],
        "virustotal": Optional[str]
    }
}
```

**í†µí•© ì¡°íšŒ êµ¬í˜„**:
```python
def query_all_sources(identifier: str, identifier_type: str) -> Dict:
    """ëª¨ë“  DB ì†ŒìŠ¤ë¥¼ ë³‘ë ¬ ì¡°íšŒí•˜ì—¬ í†µí•© ê²°ê³¼ ë°˜í™˜"""

    results = []

    # ì „í™”ë²ˆí˜¸ ì¡°íšŒ
    if identifier_type == "phone":
        results.extend([
            check_phone_thecheat(identifier),
            check_police_db("phone", identifier),
            check_counterscam(identifier)
        ])

    # URL ì¡°íšŒ
    elif identifier_type == "url":
        results.extend([
            check_url_kisa(identifier),
            check_google_safe_browsing(identifier),
            check_virustotal(identifier)
        ])

    # ê³„ì¢Œë²ˆí˜¸ ì¡°íšŒ
    elif identifier_type == "account":
        results.extend([
            check_account_thecheat(identifier),
            check_police_db("account", identifier)
        ])

    # ì´ë©”ì¼ ì¡°íšŒ
    elif identifier_type == "email":
        results.append(check_police_db("email", identifier))

    # ê²°ê³¼ í†µí•© ë° ì‚¬ì „ í™•ë¥  ê³„ì‚°
    reported_sources = [r["source"] for r in results if r.get("is_reported")]
    has_reported = len(reported_sources) > 0
    prior_probability = calculate_prior_probability(results)

    return {
        "has_reported": has_reported,
        "sources": reported_sources,
        "prior_probability": prior_probability,
        "details": {r["source"].lower(): r for r in results}
    }
```

**ì‚¬ì „ í™•ë¥  ê³„ì‚°**:
```python
def calculate_prior_probability(results: List[Dict]) -> float:
    """ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ì‚¬ì „ í™•ë¥  ê³„ì‚°

    ê°€ì¤‘ì¹˜:
    - ê³µì‹ ê¸°ê´€ (ê²½ì°°ì²­, KISA, CounterScam): 0.95
    - TheCheat (ì‹ ê³  ê±´ìˆ˜ ê¸°ë°˜): 0.7 ~ 0.95
    - Google Safe Browsing: 0.8
    - VirusTotal: 0.8 (positives/total ë¹„ìœ¨)
    """

    source_weights = {
        "Police": 0.95,
        "KISA": 0.95,
        "CounterScam": 0.95,
        "TheCheat": 0.85,  # ì‹ ê³  ê±´ìˆ˜ì— ë”°ë¼ 0.7~0.95
        "Google": 0.8,
        "VirusTotal": 0.8
    }

    weighted_sum = 0.0
    total_weight = 0.0

    for result in results:
        source = result.get("source")
        is_reported = result.get("is_reported", False)

        if source in source_weights:
            weight = source_weights[source]

            # TheCheatì˜ ê²½ìš° ì‹ ê³  ê±´ìˆ˜ ë°˜ì˜
            if source == "TheCheat" and is_reported:
                report_count = result.get("report_count", 1)
                weight = min(0.7 + (report_count / 100) * 0.25, 0.95)

            # VirusTotalì˜ ê²½ìš° íƒì§€ ë¹„ìœ¨ ë°˜ì˜
            if source == "VirusTotal" and is_reported:
                positives = result.get("positives", 0)
                total = result.get("total", 1)
                weight = (positives / total) * 0.9

            if is_reported:
                weighted_sum += weight
                total_weight += 1.0

    # í‰ê·  ê°€ì¤‘ í™•ë¥  ë°˜í™˜
    if total_weight == 0:
        return 0.0

    return min(weighted_sum / total_weight, 1.0)
```

**ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”**:
```python
from concurrent.futures import ThreadPoolExecutor, as_completed

def parallel_db_query(identifier: str, identifier_type: str) -> Dict:
    """ë³‘ë ¬ ì²˜ë¦¬ë¡œ ëª¨ë“  DBë¥¼ ë™ì‹œ ì¡°íšŒ (ì„±ëŠ¥ í–¥ìƒ)"""

    with ThreadPoolExecutor(max_workers=6) as executor:
        futures = []

        if identifier_type == "phone":
            futures.append(executor.submit(check_phone_thecheat, identifier))
            futures.append(executor.submit(check_police_db, "phone", identifier))
            futures.append(executor.submit(check_counterscam, identifier))

        elif identifier_type == "url":
            futures.append(executor.submit(check_url_kisa, identifier))
            futures.append(executor.submit(check_google_safe_browsing, identifier))
            futures.append(executor.submit(check_virustotal, identifier))

        # ê²°ê³¼ ìˆ˜ì§‘
        results = []
        for future in as_completed(futures):
            try:
                result = future.result(timeout=5)
                results.append(result)
            except Exception as e:
                print(f"DB query error: {e}")

        return query_all_sources(results)
```

---

#### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ ìƒì„±:
```bash
# TheCheat API
THECHEAT_API_KEY=your_thecheat_api_key

# KISA Open API
KISA_API_KEY=your_kisa_api_key

# Google Safe Browsing
GOOGLE_API_KEY=your_google_api_key

# VirusTotal
VIRUSTOTAL_API_KEY=your_virustotal_api_key
```

**Graceful Fallback**: API í‚¤ê°€ ì—†ëŠ” ê²½ìš°ì—ë„ ë‹¤ë¥¸ ì†ŒìŠ¤ë¡œ ê³„ì† ì¡°íšŒ ê°€ëŠ¥

### 5.3 social_graph_mcp

**ëª©ì **: ëŒ€í™” ê´€ê³„ ì‹ ë¢°ë„ ê³„ì‚°

**Input**:
```python
{
    "user_id": str,
    "contact_phone": str,
    "conversation_context": Optional[List[Dict]]
}
```

**Output**:
```python
{
    "trust_score": float,  # 0.0 ~ 1.0
    "relationship_duration_days": int,
    "message_count": int,
    "tone_consistency": float,
    "phone_change_detected": bool,
    "reasoning": str
}
```

**ì‹ ë¢°ë„ ê³„ì‚° ë¡œì§**:
```python
def calculate_trust_score(
    duration_days: int,
    message_count: int,
    tone_consistency: float,
    phone_change_detected: bool
) -> float:
    """
    ì‹ ë¢°ë„ = ê¸°ê°„(30%) + ë¹ˆë„(40%) + ì¼ê´€ì„±(30%) - ë²ˆí˜¸ë³€ê²½ í˜ë„í‹°(30%)
    """
    # ê¸°ê°„ ìŠ¤ì½”ì–´ (30ì¼ = 1.0)
    period_score = min(duration_days / 30, 1.0)

    # ë¹ˆë„ ìŠ¤ì½”ì–´ (20ê±´ = 1.0)
    frequency_score = min(message_count / 20, 1.0)

    # ì¼ê´€ì„± ìŠ¤ì½”ì–´ (ì§ì ‘ ì…ë ¥)
    consistency_score = tone_consistency

    # ë²ˆí˜¸ ë³€ê²½ í˜ë„í‹°
    penalty = 0.3 if phone_change_detected else 0

    # ì¢…í•© ê³„ì‚°
    trust_score = (
        period_score * 0.3 +
        frequency_score * 0.4 +
        consistency_score * 0.3 -
        penalty
    )

    return max(0, min(trust_score, 1.0))
```

### 5.4 entity_extractor_mcp

**ëª©ì **: ë©”ì‹œì§€ì—ì„œ ì£¼ìš” ì—”í‹°í‹° ì¶”ì¶œ

**Input**:
```python
{
    "message": str
}
```

**Output**:
```python
{
    "phone_numbers": List[str],
    "account_numbers": List[str],
    "urls": List[str],
    "organizations": List[str],
    "persons": List[str],
    "amounts": List[Dict]  # [{"value": 50000, "currency": "KRW"}]
}
```

**êµ¬í˜„ ë°©ë²•**:
- ì •ê·œì‹ íŒ¨í„´ ë§¤ì¹­ (ì „í™”ë²ˆí˜¸, ê³„ì¢Œë²ˆí˜¸, URL)
- Named Entity Recognition (ì¡°ì§ëª…, ì¸ëª…)
- ê¸ˆì•¡ ì¶”ì¶œ (ìˆ«ì + í™”í ë‹¨ìœ„)

### 5.5 bayesian_calculator_mcp

**ëª©ì **: ë² ì´ì§€ì•ˆ ì‚¬í›„ í™•ë¥  ê³„ì‚°

**Input**:
```python
{
    "pattern_confidence": float,  # context_analyzer ê²°ê³¼
    "db_prior": float,  # threat_intelligence ê²°ê³¼
    "trust_score": float,  # social_graph ê²°ê³¼
    "weights": Optional[Dict] = {
        "pattern": 0.4,
        "db": 0.3,
        "trust": 0.3
    }
}
```

**Output**:
```python
{
    "posterior_probability": float,  # P(Fraud|Evidence)
    "risk_level": str,  # "CRITICAL", "HIGH", "MEDIUM", "LOW", "SAFE"
    "confidence": float,
    "evidence_weights": Dict,
    "reasoning": str
}
```

**ê³„ì‚° ë¡œì§ (ë™ì  ì¶”ë¡  í†µí•©)**:
```python
def calculate_posterior(
    pattern_confidence: float,
    db_prior: float,
    trust_score: float,
    evidence_quality: Dict = None
) -> Dict:
    """
    ë™ì  ì¶”ë¡  ê¸°ë°˜ Bayesian ê³„ì‚° (Agent íŒë‹¨ í†µí•©)

    ê¸°ì¡´: ê³ ì • ê°€ì¤‘ì¹˜ (0.4/0.3/0.3)
    ê°œì„ : ë§¥ë½ ì¸ì‹ â†’ ë™ì  ê°€ì¤‘ì¹˜ â†’ ì¶”ë¡  íŒì •

    P(Fraud|Evidence) =
        w1(context) * pattern_confidence +
        w2(context) * db_prior +
        w3(context) * (1 - trust_score)
    """
    # Step 1: ë§¥ë½ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì • (Section 6.3.10.1)
    if evidence_quality is None:
        evidence_quality = {}

    weight_adjustment = _adjust_weights_by_context(
        pattern_confidence,
        db_prior,
        trust_score,
        evidence_quality
    )

    weights = weight_adjustment["weights"]

    # Step 2: ë™ì  ê°€ì¤‘ì¹˜ë¡œ ì‚¬í›„ í™•ë¥  ê³„ì‚°
    posterior = (
        weights["pattern"] * pattern_confidence +
        weights["db"] * db_prior +
        weights["trust"] * (1 - trust_score)
    )

    # Step 3: ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
    confidence_interval = _calculate_confidence_interval(
        posterior, evidence_quality
    )

    # Step 4: ì¦ê±° ìš”ì•½
    evidence_summary = {
        "pattern_confidence": pattern_confidence,
        "db_prior": db_prior,
        "trust_score": trust_score
    }

    # Step 5: ì¶”ë¡  ê¸°ë°˜ Risk Level íŒì • (Section 6.3.10.2)
    risk_reasoning = _reason_about_risk(
        posterior,
        confidence_interval,
        evidence_summary
    )

    # Step 6: XAI ì„¤ëª… ìƒì„± (Section 6.3.10.3)
    explanation = _generate_explanation(
        final_result={
            "posterior": posterior,
            "ci_lower": confidence_interval[0],
            "ci_upper": confidence_interval[1]
        },
        weight_adjustment=weight_adjustment,
        risk_reasoning=risk_reasoning
    )

    return {
        "posterior_probability": posterior,
        "risk_level": risk_reasoning["risk_level"],
        "confidence": risk_reasoning["confidence"],
        "evidence_weights": weights,
        "reasoning": explanation,
        "weight_adjustment_reason": weight_adjustment["reasoning"],
        "confidence_interval": confidence_interval,
        "base_risk": risk_reasoning.get("base_risk")
    }

def _adjust_weights_by_context(
    pattern_conf: float,
    db_prior: float,
    trust_score: float,
    evidence_quality: Dict
) -> Dict[str, float]:
    """
    Agentê°€ ìƒí™©ì„ íŒë‹¨í•˜ì—¬ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì •
    (Section 6.3.10.1ì˜ êµ¬í˜„)
    """
    weights = {"pattern": 0.4, "db": 0.3, "trust": 0.3}
    reasoning = "ê¸°ë³¸ ê· í˜• ê°€ì¤‘ì¹˜"

    # Case 1: ì¥ê¸° ëŒ€í™” ê´€ê³„
    if trust_score > 0.8 and evidence_quality.get("conversation_period", 0) > 30:
        weights = {"pattern": 0.2, "db": 0.2, "trust": 0.6}
        reasoning = "ì¥ê¸° ê´€ê³„ â†’ ì‹ ë¢°ë„ ì¤‘ì‹¬"

    # Case 2: ë‹¤ì¤‘ DB ì‹ ê³ 
    elif db_prior > 0.85 and evidence_quality.get("db_sources", 0) >= 3:
        weights = {"pattern": 0.25, "db": 0.55, "trust": 0.2}
        reasoning = "ë‹¤ì¤‘ DB ì‹ ê³  â†’ DB ì¤‘ì‹¬"

    # Case 3: íŒ¨í„´ ë§¤ì¹­ë§Œ ê°•í•¨
    elif pattern_conf > 0.85 and db_prior < 0.3 and trust_score < 0.4:
        weights = {"pattern": 0.6, "db": 0.2, "trust": 0.2}
        reasoning = "íŒ¨í„´ë§Œ ê°•ë ¥ â†’ íŒ¨í„´ ì¤‘ì‹¬"

    # Case 4: ëª¨ë“  ì¦ê±° ì•½í•¨
    elif pattern_conf < 0.5 and db_prior < 0.5 and trust_score < 0.5:
        weights = {"pattern": 0.35, "db": 0.35, "trust": 0.3}
        reasoning = "ì¦ê±° ì•½í•¨ â†’ ê· í˜• + ë³´ìˆ˜ì "

    return {"weights": weights, "reasoning": reasoning}

def _calculate_confidence_interval(
    posterior: float,
    evidence_quality: Dict
) -> Tuple[float, float]:
    """
    ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ì‹ ë¢° êµ¬ê°„ ê³„ì‚°
    """
    # ì¦ê±° í’ˆì§ˆì— ë”°ë¥¸ ë¶ˆí™•ì‹¤ì„± ì¶”ì •
    uncertainty = 0.1  # ê¸°ë³¸ê°’

    if evidence_quality.get("pattern_match_count", 0) < 2:
        uncertainty += 0.05

    if evidence_quality.get("db_sources", 0) == 0:
        uncertainty += 0.05

    if evidence_quality.get("conversation_period", 0) < 7:
        uncertainty += 0.05

    lower = max(0.0, posterior - uncertainty)
    upper = min(1.0, posterior + uncertainty)

    return (lower, upper)

def _reason_about_risk(
    posterior: float,
    confidence_interval: Tuple[float, float],
    evidence_summary: Dict
) -> Dict:
    """
    ì¶”ë¡  ê¸°ë°˜ Risk Level íŒì •
    (Section 6.3.10.2ì˜ êµ¬í˜„)
    """
    uncertainty = confidence_interval[1] - confidence_interval[0]
    evidence_alignment = _check_evidence_alignment(evidence_summary)

    # ê¸°ë³¸ threshold íŒë‹¨
    if posterior >= 0.9:
        base_risk = "CRITICAL"
    elif posterior >= 0.75:
        base_risk = "HIGH"
    elif posterior >= 0.5:
        base_risk = "MEDIUM"
    else:
        base_risk = "LOW"

    # Agent ì¶”ë¡ 
    reasoning_steps = []
    final_risk = base_risk

    # Step 1: Uncertainty ê²€í† 
    if uncertainty > 0.2 and base_risk == "CRITICAL":
        final_risk = "HIGH"
        reasoning_steps.append("ë¶ˆí™•ì‹¤ì„± ë†’ìŒ â†’ í•˜í–¥")

    # Step 2: Evidence Alignment ê²€í† 
    if evidence_alignment == "conflicting" and base_risk in ["HIGH", "CRITICAL"]:
        final_risk = "MEDIUM"
        reasoning_steps.append("ì¦ê±° ì¶©ëŒ â†’ ë³´ìˆ˜ì  í•˜í–¥")

    # Step 3: ê²½ê³„ì„  ì¼€ì´ìŠ¤
    if 0.65 <= posterior < 0.75:
        if uncertainty > 0.15 and evidence_alignment == "conflicting":
            final_risk = "MEDIUM"
            reasoning_steps.append("ê²½ê³„ì„  + ë¶ˆí™•ì‹¤ì„± â†’ MEDIUM")
        elif evidence_alignment == "strong":
            final_risk = "HIGH"
            reasoning_steps.append("ê²½ê³„ì„  but ì¦ê±° ì¼ê´€ â†’ HIGH")

    return {
        "risk_level": final_risk,
        "base_risk": base_risk,
        "uncertainty": uncertainty,
        "reasoning": " | ".join(reasoning_steps) if reasoning_steps else "ê¸°ë³¸ íŒì •",
        "confidence": 1.0 - uncertainty
    }

def _check_evidence_alignment(evidence_summary: Dict) -> str:
    """
    ì¦ê±° ê°„ ì •ë ¬ ìƒíƒœ ë¶„ì„
    """
    pattern_conf = evidence_summary.get("pattern_confidence", 0)
    db_prior = evidence_summary.get("db_prior", 0)
    trust_score = evidence_summary.get("trust_score", 0)

    # ê°•í•œ ì •ë ¬
    if (pattern_conf > 0.8 and db_prior > 0.8 and trust_score < 0.3) or \
       (pattern_conf < 0.3 and db_prior < 0.3 and trust_score > 0.8):
        return "strong"

    # ì¶©ëŒ
    if (pattern_conf > 0.8 and trust_score > 0.8) or \
       (db_prior > 0.8 and trust_score > 0.8):
        return "conflicting"

    return "moderate"

def _generate_explanation(
    final_result: Dict,
    weight_adjustment: Dict,
    risk_reasoning: Dict
) -> str:
    """
    XAI ì„¤ëª… ìƒì„±
    (Section 6.3.10.3ì˜ êµ¬í˜„)
    """
    return f"""
1ï¸âƒ£ ê°€ì¤‘ì¹˜: {weight_adjustment['reasoning']}
2ï¸âƒ£ ì‚¬í›„í™•ë¥ : {final_result['posterior']:.1%} (CI: [{final_result['ci_lower']:.1%}, {final_result['ci_upper']:.1%}])
3ï¸âƒ£ Risk: {risk_reasoning['risk_level']} - {risk_reasoning['reasoning']}
4ï¸âƒ£ ì‹ ë¢°ë„: {risk_reasoning['confidence']:.1%}
""".strip()
```

### 5.6 scam_case_rag_mcp

**ëª©ì **: ìœ ì‚¬ í”¼ì‹± ì‚¬ë¡€ ê²€ìƒ‰ (RAG)

**Input**:
```python
{
    "message": str,
    "top_k": int = 3
}
```

**Output**:
```python
{
    "similar_cases": List[Dict],  # ìœ ì‚¬ ì‚¬ë¡€ top_kê°œ
    "similarity_scores": List[float],
    "reasoning": str
}
```

**êµ¬í˜„ ë°©ë²•**:
1. ë©”ì‹œì§€ ì„ë² ë”© ìƒì„± (OpenAI Embedding / Sentence-BERT)
2. ë²¡í„° DB ê²€ìƒ‰ (pgvector / Pinecone)
3. Cosine Similarity ê¸°ë°˜ Top-K ë°˜í™˜

**ì˜ˆì‹œ ì¶œë ¥**:
```python
{
    "similar_cases": [
        {
            "id": 123,
            "category": "A-1",
            "message_pattern": "ì—„ë§ˆ, í° ê³ ì¥ë‚˜ì„œ ë²ˆí˜¸ ë°”ë€œ",
            "similarity": 0.95
        },
        {
            "id": 456,
            "category": "A-1",
            "message_pattern": "ì•„ë¹ , ê¸‰í•˜ê²Œ ëˆ ì¢€ ë³´ë‚´ì¤˜",
            "similarity": 0.87
        }
    ]
}
```

---

## 6. í•µì‹¬ ì•Œê³ ë¦¬ì¦˜

### 6.1 ReAct Loop ì—”ì§„

**íŒŒì¼**: `agent/core/kanana_agent.py`

```python
class KananaAgent:
    """
    ReAct Loop ì‹¤í–‰ ì—”ì§„

    Thought â†’ Action â†’ Observation ë°˜ë³µ (ìµœëŒ€ 5 ì‚¬ì´í´)
    """

    def __init__(self, llm_client, mcp_tools: Dict):
        self.llm = llm_client
        self.tools = mcp_tools
        self.max_cycles = 5

    def analyze(self, message: str, context: Dict) -> Dict:
        """
        ë©”ì‹œì§€ ë¶„ì„ ë©”ì¸ í•¨ìˆ˜
        """
        observations = []

        for cycle in range(1, self.max_cycles + 1):
            # Step 1: Thought
            thought = self._think(message, context, observations)

            # ì¢…ë£Œ ì¡°ê±´
            if thought["action"] == "FINAL_ANSWER":
                break

            # Step 2: Action
            action_name = thought["action"]

            # Step 3: Observation
            observation = self._execute_tool(
                action_name,
                message,
                context
            )

            observations.append({
                "cycle": cycle,
                "thought": thought["reasoning"],
                "action": action_name,
                "observation": observation
            })

        # Step 4: Bayesian ìµœì¢… íŒë‹¨
        final_result = self._calculate_final_risk(observations)

        return {
            "risk_level": final_result["risk_level"],
            "confidence": final_result["confidence"],
            "decision_process": observations,
            "bayesian_result": final_result,
            "recommendations": self._generate_recommendations(final_result)
        }

---

### 6.3.10 Agentì˜ ë™ì  ì¶”ë¡  ë° íŒë‹¨ ë¡œì§

**í•µì‹¬ ì§ˆë¬¸**: "ê·¸ëƒ¥ ê³ ì •ëœ ìˆ˜ì‹ ì•„ë‹Œê°€ìš”? Agentì˜ 'íŒë‹¨'ì´ ì–´ë”” ìˆë‚˜ìš”?"

**ë‹µë³€**: Agent BëŠ” ë‹¨ìˆœ ê³„ì‚°ê¸°ê°€ ì•„ë‹ˆë¼, **ë§¥ë½ì„ ì´í•´í•˜ê³  ë™ì ìœ¼ë¡œ ì¶”ë¡ í•˜ëŠ” ì§€ëŠ¥í˜• Agent**ì…ë‹ˆë‹¤.

---

#### 6.3.10.1 ë§¥ë½ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì • (Context-Aware Weighting)

**ë¬¸ì œì **: ê³ ì •ëœ `0.4*pattern + 0.3*db + 0.3*trust`ëŠ” ëª¨ë“  ìƒí™©ì—ì„œ ë™ì¼ â†’ ë‹¨ìˆœ ê³„ì‚°ê¸°

**í•´ê²°ì±…**: Agentê°€ **ìƒí™©ì„ íŒë‹¨**í•˜ì—¬ ê°€ì¤‘ì¹˜ë¥¼ **ë™ì ìœ¼ë¡œ ì¡°ì •**

```python
def _adjust_weights_by_context(
    self,
    pattern_conf: float,
    db_prior: float,
    trust_score: float,
    evidence_quality: Dict
) -> Dict[str, float]:
    """
    Agentê°€ ìƒí™©ì„ íŒë‹¨í•˜ì—¬ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì •

    ì´ë¡ ì  ê·¼ê±°:
    - Yao et al. (2023): ReAct AgentëŠ” ë§¥ë½ì— ë”°ë¼ ì „ëµ ì¡°ì •
    - ê¸ˆê°ì› í†µê³„: ì¥ê¸° ê´€ê³„ëŠ” FP(False Positive) 90% ê°ì†Œ
    """
    weights = {"pattern": 0.4, "db": 0.3, "trust": 0.3}
    reasoning = "ê¸°ë³¸ ê· í˜• ê°€ì¤‘ì¹˜"

    # Case 1: ì¥ê¸° ëŒ€í™” ê´€ê³„ (ì‹ ë¢°ë„ê°€ ê²°ì •ì )
    if trust_score > 0.8 and evidence_quality.get("conversation_period", 0) > 30:
        weights = {"pattern": 0.2, "db": 0.2, "trust": 0.6}
        reasoning = "ğŸ¤” ì¥ê¸° ê´€ê³„(30ì¼+) + ë†’ì€ ì‹ ë¢°ë„ â†’ ì‹ ë¢°ë„ ì¤‘ì‹¬ íŒë‹¨ (FP ìœ„í—˜ 90% ê°ì†Œ)"

    # Case 2: ë‹¤ì¤‘ DB ì‹ ê³  (DBê°€ ê²°ì •ì )
    elif db_prior > 0.85 and evidence_quality.get("db_sources", 0) >= 3:
        weights = {"pattern": 0.25, "db": 0.55, "trust": 0.2}
        reasoning = "ğŸš¨ 3ê°œ ì´ìƒ DB ì‹ ê³  + ë†’ì€ prior â†’ DB ì¤‘ì‹¬ íŒë‹¨ (ì •í™•ë„ 95%+)"

    # Case 3: íŒ¨í„´ ë§¤ì¹­ë§Œ ê°•í•¨ (DB/Trust ì•½í•¨)
    elif pattern_conf > 0.85 and db_prior < 0.3 and trust_score < 0.4:
        weights = {"pattern": 0.6, "db": 0.2, "trust": 0.2}
        reasoning = "âš ï¸ íŒ¨í„´ë§Œ ê°•ë ¥ + DB/Trust ì—†ìŒ â†’ íŒ¨í„´ ì¤‘ì‹¬ íŒë‹¨ (ì‹ ì¢… ìˆ˜ë²• ëŒ€ì‘)"

    # Case 4: ëª¨ë“  ì¦ê±°ê°€ ì•½í•¨ (ê· í˜• ì ‘ê·¼)
    elif pattern_conf < 0.5 and db_prior < 0.5 and trust_score < 0.5:
        weights = {"pattern": 0.35, "db": 0.35, "trust": 0.3}
        reasoning = "ğŸ¤· ëª¨ë“  ì¦ê±° ì•½í•¨ â†’ ê· í˜• ê°€ì¤‘ì¹˜ + ë³´ìˆ˜ì  ì ‘ê·¼"

    return {
        "weights": weights,
        "reasoning": reasoning,
        "evidence_quality": evidence_quality
    }
```

**ì˜ˆì‹œ**:
```python
# âŒ ê¸°ì¡´ (ê³ ì • ê³„ì‚°)
posterior = 0.4 * 0.92 + 0.3 * 0.15 + 0.3 * 0.95 = 0.698 â†’ HIGH

# âœ… Agent íŒë‹¨ (ë™ì  ì¡°ì •)
# "DBì— ì‹ ê³ ëŠ” ì—†ì§€ë§Œ, 1ë…„ ì „ë¶€í„° ëŒ€í™” ì´ë ¥ì´ ìˆë„¤? ğŸ¤”"
weights = {"pattern": 0.2, "db": 0.2, "trust": 0.6}
posterior = 0.2 * 0.92 + 0.2 * 0.15 + 0.6 * 0.95 = 0.784 â†’ MEDIUM
reasoning = "ì¥ê¸° ê´€ê³„ + ë†’ì€ ì‹ ë¢°ë„ â†’ FP ìœ„í—˜ ê³ ë ¤í•˜ì—¬ MEDIUM"
```

**ì´ë¡ ì  ê·¼ê±°**:
- **Yao et al. (2023)**: ReAct AgentëŠ” observationì— ë”°ë¼ ì „ëµ ì¡°ì •
- **ê¸ˆê°ì› í†µê³„**: 30ì¼+ ëŒ€í™” ê´€ê³„ëŠ” FP 90% ê°ì†Œ
- **Cialdini (2021)**: Liking principleì€ ì¥ê¸° ê´€ê³„ì—ì„œ ê°•í™”

---

#### 6.3.10.2 ì¶”ë¡  ê¸°ë°˜ Risk Level íŒì •

**ë¬¸ì œì **: ë‹¨ìˆœ threshold ë¹„êµ (`if posterior >= 0.9: return "CRITICAL"`)

**í•´ê²°ì±…**: Agentê°€ **ë¶ˆí™•ì‹¤ì„±**ê³¼ **ì¦ê±° ì •ë ¬**ì„ **ì¶”ë¡ **í•˜ì—¬ íŒë‹¨

```python
def _reason_about_risk(
    self,
    posterior: float,
    confidence_interval: Tuple[float, float],
    evidence_summary: Dict
) -> Dict:
    """
    Agentê°€ ë¶ˆí™•ì‹¤ì„±ê³¼ ì¦ê±° ì •ë ¬ì„ ì¶”ë¡ í•˜ì—¬ risk level ê²°ì •

    ì´ë¡ ì  ê·¼ê±°:
    - FDA Guidance: ì˜ë£Œ AIëŠ” uncertainty-aware íŒë‹¨ í•„ìˆ˜
    - ê¸ˆê°ì› ì›ì¹™: ë¶ˆí™•ì‹¤ì„± ë†’ì„ ë•Œ ë³´ìˆ˜ì  ì ‘ê·¼
    """
    uncertainty = confidence_interval[1] - confidence_interval[0]
    evidence_alignment = self._check_evidence_alignment(evidence_summary)

    # ê¸°ë³¸ threshold íŒë‹¨
    if posterior >= 0.9:
        base_risk = "CRITICAL"
    elif posterior >= 0.75:
        base_risk = "HIGH"
    elif posterior >= 0.5:
        base_risk = "MEDIUM"
    else:
        base_risk = "LOW"

    # Agentì˜ ì¶”ë¡  ë¡œì§
    reasoning_steps = []
    final_risk = base_risk

    # Step 1: Uncertainty ê²€í† 
    if uncertainty > 0.2:
        reasoning_steps.append(f"âš ï¸ ë¶ˆí™•ì‹¤ì„± ë†’ìŒ (CI í­: {uncertainty:.2f})")
        if base_risk == "CRITICAL":
            final_risk = "HIGH"
            reasoning_steps.append("â†’ CRITICAL â†’ HIGH í•˜í–¥ (ë¶ˆí™•ì‹¤ì„± ê³ ë ¤)")

    # Step 2: Evidence Alignment ê²€í† 
    if evidence_alignment == "conflicting":
        reasoning_steps.append("ğŸ¤” ì¦ê±° ì¶©ëŒ ê°ì§€ (pattern vs. trust ë¶ˆì¼ì¹˜)")
        if base_risk in ["HIGH", "CRITICAL"]:
            final_risk = "MEDIUM"
            reasoning_steps.append("â†’ ë³´ìˆ˜ì  MEDIUM í•˜í–¥ (ì¦ê±° ì¶©ëŒ)")

    # Step 3: ê²½ê³„ì„  ì¼€ì´ìŠ¤ ì¶”ë¡ 
    if 0.65 <= posterior < 0.75:
        reasoning_steps.append("ğŸ¯ ê²½ê³„ì„  ì¼€ì´ìŠ¤ (0.65~0.75)")
        if uncertainty > 0.15 and evidence_alignment == "conflicting":
            final_risk = "MEDIUM"
            reasoning_steps.append("â†’ ê²½ê³„ì„  + ë¶ˆí™•ì‹¤ì„± + ì¶©ëŒ = MEDIUM (ë³´ìˆ˜ì )")
        elif evidence_alignment == "strong":
            final_risk = "HIGH"
            reasoning_steps.append("â†’ ê²½ê³„ì„ ì´ì§€ë§Œ ì¦ê±° ì¼ê´€ = HIGH ìœ ì§€")

    return {
        "risk_level": final_risk,
        "base_risk": base_risk,
        "posterior": posterior,
        "uncertainty": uncertainty,
        "evidence_alignment": evidence_alignment,
        "reasoning": " | ".join(reasoning_steps),
        "confidence": 1.0 - uncertainty
    }

def _check_evidence_alignment(self, evidence_summary: Dict) -> str:
    """
    ì¦ê±° ê°„ ì •ë ¬ ìƒíƒœ ë¶„ì„
    """
    pattern_conf = evidence_summary.get("pattern_confidence", 0)
    db_prior = evidence_summary.get("db_prior", 0)
    trust_score = evidence_summary.get("trust_score", 0)

    # ëª¨ë“  ì¦ê±°ê°€ ì¼ê´€ë˜ê²Œ ë†’ìŒ
    if pattern_conf > 0.8 and db_prior > 0.8 and trust_score < 0.3:
        return "strong"  # ê°•í•œ ì •ë ¬

    # ëª¨ë“  ì¦ê±°ê°€ ì¼ê´€ë˜ê²Œ ë‚®ìŒ
    if pattern_conf < 0.3 and db_prior < 0.3 and trust_score > 0.8:
        return "strong"  # ê°•í•œ ì •ë ¬ (ë°˜ëŒ€ ë°©í–¥)

    # ì¦ê±°ê°€ ì¶©ëŒ (ì˜ˆ: pattern ë†’ì§€ë§Œ trust ë†’ìŒ)
    if (pattern_conf > 0.8 and trust_score > 0.8) or \
       (db_prior > 0.8 and trust_score > 0.8):
        return "conflicting"  # ì¶©ëŒ

    return "moderate"  # ë³´í†µ ì •ë ¬
```

**ì˜ˆì‹œ**:
```python
# âŒ ê¸°ì¡´ (ë‹¨ìˆœ threshold)
posterior = 0.73 â†’ if >= 0.75: HIGH else: MEDIUM â†’ MEDIUM

# âœ… Agent ì¶”ë¡ 
posterior = 0.73
uncertainty = 0.18  # CI: [0.64, 0.82]
evidence_alignment = "strong"  # pattern/db ì¼ì¹˜

reasoning_steps = [
    "ğŸ¯ ê²½ê³„ì„  ì¼€ì´ìŠ¤ (0.73)",
    "âš ï¸ ë¶ˆí™•ì‹¤ì„± ë‹¤ì†Œ ë†’ìŒ (0.18)",
    "âœ… ì¦ê±° ê°•í•˜ê²Œ ì •ë ¬",
    "â†’ ê²½ê³„ì„ ì´ì§€ë§Œ ì¦ê±° ì¼ê´€ = HIGH ìœ ì§€ (ìƒí–¥)"
]
final_risk = "HIGH"
```

---

#### 6.3.10.3 ì„¤ëª… ê°€ëŠ¥í•œ ì˜ì‚¬ê²°ì • (Explainable AI)

**ë¬¸ì œì **: ì‚¬ìš©ìëŠ” "ì™œ ì´ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€" ì•Œ ìˆ˜ ì—†ìŒ

**í•´ê²°ì±…**: Agentê°€ **íŒë‹¨ ê·¼ê±°**ë¥¼ **ìì—°ì–´ë¡œ ì„¤ëª…**

```python
def _generate_explanation(
    self,
    final_result: Dict,
    weight_adjustment: Dict,
    risk_reasoning: Dict
) -> str:
    """
    Agentì˜ íŒë‹¨ ê³¼ì •ì„ ìì—°ì–´ë¡œ ì„¤ëª…

    ì´ë¡ ì  ê·¼ê±°:
    - EU AI Act: High-risk AIëŠ” ì„¤ëª… ê°€ëŠ¥ì„± í•„ìˆ˜
    - Ribeiro et al. (2016): LIME - ì„¤ëª… ê°€ëŠ¥í•œ ML
    """
    explanation_parts = []

    # Part 1: ê°€ì¤‘ì¹˜ ì¡°ì • ì´ìœ 
    explanation_parts.append(f"1ï¸âƒ£ **ê°€ì¤‘ì¹˜ ì¡°ì •**: {weight_adjustment['reasoning']}")
    explanation_parts.append(f"   - Pattern: {weight_adjustment['weights']['pattern']:.1%}")
    explanation_parts.append(f"   - DB: {weight_adjustment['weights']['db']:.1%}")
    explanation_parts.append(f"   - Trust: {weight_adjustment['weights']['trust']:.1%}")

    # Part 2: ì‚¬í›„ í™•ë¥  ê³„ì‚°
    explanation_parts.append(f"\n2ï¸âƒ£ **ì‚¬í›„ í™•ë¥ **: {final_result['posterior']:.1%}")
    explanation_parts.append(f"   - ì‹ ë¢° êµ¬ê°„: [{final_result['ci_lower']:.1%}, {final_result['ci_upper']:.1%}]")
    explanation_parts.append(f"   - ë¶ˆí™•ì‹¤ì„±: {risk_reasoning['uncertainty']:.1%}")

    # Part 3: Risk Level íŒë‹¨
    explanation_parts.append(f"\n3ï¸âƒ£ **Risk Level**: {risk_reasoning['risk_level']}")
    explanation_parts.append(f"   - ì¶”ë¡  ê³¼ì •: {risk_reasoning['reasoning']}")

    # Part 4: ì‹ ë¢°ë„
    explanation_parts.append(f"\n4ï¸âƒ£ **ì‹ ë¢°ë„**: {risk_reasoning['confidence']:.1%}")

    return "\n".join(explanation_parts)
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```
1ï¸âƒ£ **ê°€ì¤‘ì¹˜ ì¡°ì •**: ğŸ¤” ì¥ê¸° ê´€ê³„(30ì¼+) + ë†’ì€ ì‹ ë¢°ë„ â†’ ì‹ ë¢°ë„ ì¤‘ì‹¬ íŒë‹¨ (FP ìœ„í—˜ 90% ê°ì†Œ)
   - Pattern: 20.0%
   - DB: 20.0%
   - Trust: 60.0%

2ï¸âƒ£ **ì‚¬í›„ í™•ë¥ **: 78.4%
   - ì‹ ë¢° êµ¬ê°„: [72.1%, 84.7%]
   - ë¶ˆí™•ì‹¤ì„±: 12.6%

3ï¸âƒ£ **Risk Level**: MEDIUM
   - ì¶”ë¡  ê³¼ì •: ğŸ¯ ê²½ê³„ì„  ì¼€ì´ìŠ¤ (0.78) | âœ… ì¦ê±° ì •ë ¬ | â†’ ì¥ê¸° ê´€ê³„ ê³ ë ¤í•˜ì—¬ MEDIUM

4ï¸âƒ£ **ì‹ ë¢°ë„**: 87.4%
```

---

#### 6.3.10.4 ê²€ì¦ ë¡œë“œë§µì— ì¶”ë¡  ë¡œì§ ì¶”ê°€

**Phase 1 (í˜„ì¬ - ì´ë¡ ì )**:
- âœ… ë™ì  ê°€ì¤‘ì¹˜ ì¡°ì • ë¡œì§ ì„¤ê³„
- âœ… ì¶”ë¡  ê¸°ë°˜ risk íŒì • ì„¤ê³„
- âœ… XAI ì„¤ëª… ìƒì„± ë¡œì§ ì„¤ê³„

**Phase 2 (2025 Q1 - 100ê±´ Pilot)**:
```python
validation_metrics = {
    "weight_adjustment_accuracy": 0.0,  # ê°€ì¤‘ì¹˜ ì¡°ì •ì´ ì •í™•ë„ í–¥ìƒì— ê¸°ì—¬í–ˆëŠ”ê°€?
    "reasoning_consistency": 0.0,        # ì¶”ë¡  ë¡œì§ì´ ì¼ê´€ì„± ìˆëŠ”ê°€?
    "explanation_quality": 0.0,          # ì„¤ëª…ì´ ì‚¬ìš©ìì—ê²Œ ìœ ìš©í•œê°€?
    "false_positive_reduction": 0.0      # ë™ì  íŒë‹¨ì´ FPë¥¼ ì¤„ì˜€ëŠ”ê°€?
}
```

**Phase 3 (2025 Q2 - 1,000ê±´ ì‹¤ì¦)**:
- ê°€ì¤‘ì¹˜ ì¡°ì • ê·œì¹™ ìµœì í™” (A/B í…ŒìŠ¤íŠ¸)
- ì¶”ë¡  ë¡œì§ ê°œì„  (ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜)
- XAI ì„¤ëª… í’ˆì§ˆ í–¥ìƒ

**Phase 4 (2025 Q3~ - ìë™ í•™ìŠµ)**:
```python
def _learn_weight_adjustment(self, validation_results: List[Dict]):
    """
    ê²€ì¦ ê²°ê³¼ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì • ê·œì¹™ ìë™ í•™ìŠµ

    ì˜ˆ: ì¥ê¸° ê´€ê³„ì—ì„œ FPê°€ ë§ì´ ì¤„ì—ˆë‹¤ë©´
        â†’ trust ê°€ì¤‘ì¹˜ë¥¼ 0.6 â†’ 0.7ë¡œ ìƒí–¥
    """
    pass
```

---

#### 6.3.10.5 êµìˆ˜ë‹˜ ì˜ˆìƒ ì§ˆë¬¸

**Q6: "ê·¸ëƒ¥ ê³ ì •ëœ ìˆ˜ì‹ ì•„ë‹Œê°€ìš”? Agentì˜ 'íŒë‹¨'ì´ ì–´ë”” ìˆë‚˜ìš”?"**

**A6**:
> **ì•„ë‹ˆìš”, Agent BëŠ” ë‹¨ìˆœ ê³„ì‚°ê¸°ê°€ ì•„ë‹™ë‹ˆë‹¤.**
>
> **Agentì˜ íŒë‹¨ ëŠ¥ë ¥ 3ê°€ì§€**:
>
> 1. **ë§¥ë½ ì¸ì‹ ê°€ì¤‘ì¹˜ ì¡°ì •** (Context-Aware Weighting)
>    - ì˜ˆ: "ì¥ê¸° ê´€ê³„ë©´ ì‹ ë¢°ë„ ì¤‘ì‹¬ íŒë‹¨" â†’ `0.4/0.3/0.3` â†’ `0.2/0.2/0.6`
>    - ê·¼ê±°: Yao et al. (2023) ReAct Agent, ê¸ˆê°ì› í†µê³„
>
> 2. **ì¶”ë¡  ê¸°ë°˜ Risk íŒì •** (Reasoning-Based Decision)
>    - ì˜ˆ: "ê²½ê³„ì„  ì¼€ì´ìŠ¤ + ì¦ê±° ì¶©ëŒ" â†’ ë³´ìˆ˜ì  MEDIUM í•˜í–¥
>    - ê·¼ê±°: FDA Guidance (uncertainty-aware AI)
>
> 3. **ì„¤ëª… ê°€ëŠ¥í•œ ì˜ì‚¬ê²°ì •** (Explainable AI)
>    - ì˜ˆ: "ì™œ ì´ë ‡ê²Œ íŒë‹¨í–ˆëŠ”ì§€" ìì—°ì–´ ì„¤ëª…
>    - ê·¼ê±°: EU AI Act (ì„¤ëª… ê°€ëŠ¥ì„± í•„ìˆ˜)
>
> **ì½”ë“œ ì¦ê±°**: Section 6.3.10.1~10.3 ì°¸ì¡°
>
> **ê²€ì¦ ê³„íš**: Phase 2~4ì—ì„œ ë™ì  íŒë‹¨ ì •í™•ë„ ì¸¡ì • (ë¬¸ì„œ Section 6.3.10.4)

---

    def _think(
        self,
        message: str,
        context: Dict,
        observations: List[Dict]
    ) -> Dict:
        """
        Kanana LLMì„ ì‚¬ìš©í•œ Thought ìƒì„±
        """
        prompt = self._build_prompt(message, context, observations)

        response = self.llm.generate(prompt)

        return {
            "reasoning": response["reasoning"],
            "action": response["next_action"]
        }

    def _execute_tool(
        self,
        action_name: str,
        message: str,
        context: Dict
    ) -> Dict:
        """
        MCP ë„êµ¬ ì‹¤í–‰
        """
        tool = self.tools.get(action_name)

        if not tool:
            raise ValueError(f"Unknown tool: {action_name}")

        return tool.execute(message=message, context=context)

    def _calculate_final_risk(self, observations: List[Dict]) -> Dict:
        """
        ë™ì  ì¶”ë¡  ê¸°ë°˜ ìµœì¢… ìœ„í—˜ë„ ê³„ì‚° (Agent íŒë‹¨ í†µí•©)

        ê¸°ì¡´: ê³ ì • ê°€ì¤‘ì¹˜ë¡œ ë‹¨ìˆœ ê³„ì‚°
        ê°œì„ : ë§¥ë½ ì¸ì‹ â†’ ê°€ì¤‘ì¹˜ ì¡°ì • â†’ ì¶”ë¡  ê¸°ë°˜ íŒì • â†’ XAI ì„¤ëª…
        """
        # Step 1: observationsì—ì„œ í•„ìš”í•œ ê°’ ì¶”ì¶œ
        pattern_conf = self._extract_value(
            observations, "context_analyzer", "confidence", default=0.5
        )
        db_prior = self._extract_value(
            observations, "threat_intelligence", "db_prior", default=0.0
        )
        trust_score = self._extract_value(
            observations, "social_graph", "trust_score", default=0.5
        )

        # Step 1.5: ì¦ê±° í’ˆì§ˆ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (NEW!)
        evidence_quality = {
            "conversation_period": self._extract_value(
                observations, "social_graph", "conversation_days", default=0
            ),
            "db_sources": self._extract_value(
                observations, "threat_intelligence", "source_count", default=0
            ),
            "pattern_match_count": self._extract_value(
                observations, "context_analyzer", "matched_patterns", default=0
            )
        }

        # Step 2: ë§¥ë½ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ë™ì  ì¡°ì • (NEW! - Section 6.3.10.1)
        weight_adjustment = self._adjust_weights_by_context(
            pattern_conf=pattern_conf,
            db_prior=db_prior,
            trust_score=trust_score,
            evidence_quality=evidence_quality
        )

        weights = weight_adjustment["weights"]

        # Step 3: ë™ì  ê°€ì¤‘ì¹˜ë¡œ ì‚¬í›„ í™•ë¥  ê³„ì‚°
        posterior = (
            weights["pattern"] * pattern_conf +
            weights["db"] * db_prior +
            weights["trust"] * (1 - trust_score)
        )

        # Step 3.5: ì‹ ë¢° êµ¬ê°„ ê³„ì‚° (ë¶ˆí™•ì‹¤ì„± ì¶”ì •)
        confidence_interval = self._calculate_confidence_interval(
            posterior=posterior,
            evidence_quality=evidence_quality
        )

        # Step 4: ì¦ê±° ìš”ì•½ (ì¶”ë¡ ìš©)
        evidence_summary = {
            "pattern_confidence": pattern_conf,
            "db_prior": db_prior,
            "trust_score": trust_score
        }

        # Step 5: ì¶”ë¡  ê¸°ë°˜ Risk Level íŒì • (NEW! - Section 6.3.10.2)
        risk_reasoning = self._reason_about_risk(
            posterior=posterior,
            confidence_interval=confidence_interval,
            evidence_summary=evidence_summary
        )

        # Step 6: XAI ì„¤ëª… ìƒì„± (NEW! - Section 6.3.10.3)
        explanation = self._generate_explanation(
            final_result={
                "posterior": posterior,
                "ci_lower": confidence_interval[0],
                "ci_upper": confidence_interval[1]
            },
            weight_adjustment=weight_adjustment,
            risk_reasoning=risk_reasoning
        )

        # Step 7: ìµœì¢… ê²°ê³¼ ë°˜í™˜
        return {
            "posterior_probability": posterior,
            "risk_level": risk_reasoning["risk_level"],
            "confidence": risk_reasoning["confidence"],
            "evidence_weights": weights,
            "reasoning": explanation,
            "weight_adjustment_reason": weight_adjustment["reasoning"],
            "confidence_interval": confidence_interval,
            "base_risk": risk_reasoning.get("base_risk", risk_reasoning["risk_level"])
        }
```

### 6.2 System Prompt êµ¬ì¡°

**íŒŒì¼**: `agent/prompts/system_prompt.py`

```python
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤í†¡ ë©”ì‹œì§€ ê¸°ë°˜ í”¼ì‹± íƒì§€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

## ëª©í‘œ
ì‚¬ìš©ìë¥¼ í”¼ì‹± ì‚¬ê¸°ë¡œë¶€í„° ë³´í˜¸í•˜ê¸° ìœ„í•´ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ê³  ìœ„í—˜ë„ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.

## ì›ì¹™
1. **ë§¥ë½ ìš°ì„ **: 1ê°œì›” ëŒ€í™” ì´ë ¥ > DB ì‹ ê³  1ê±´
2. **ë¹„íŒì  ì‚¬ê³ **: DB ì‹ ê³  = ì‚¬ì „ í™•ë¥ , ì ˆëŒ€ ì§„ë¦¬ ì•„ë‹˜
3. **ë³´ìˆ˜ì  íŒë‹¨**: ë¶ˆí™•ì‹¤í•˜ë©´ MEDIUM (ì‚¬ìš©ì í™•ì¸ ìœ ë„)

## ê°€ëŠ¥í•œ ë„êµ¬ (ìˆœì„œ ê¶Œì¥)
1. context_analyzer_mcp: ë©”ì‹œì§€ íŒ¨í„´ ë¶„ë¥˜ (A-1~C-3)
2. threat_intelligence_mcp: DB ì‹ ê³  ì´ë ¥ ì¡°íšŒ
3. social_graph_mcp: ëŒ€í™” ê´€ê³„ ì‹ ë¢°ë„ ê³„ì‚°
4. entity_extractor_mcp: ì „í™”ë²ˆí˜¸, ê³„ì¢Œë²ˆí˜¸ ì¶”ì¶œ
5. bayesian_calculator_mcp: ìµœì¢… í™•ë¥  ê³„ì‚° (í•„ìˆ˜)
6. scam_case_rag_mcp: ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰

## ì¶œë ¥ í˜•ì‹
{
    "reasoning": "í˜„ì¬ ìƒí™©ì— ëŒ€í•œ ì‚¬ê³  ê³¼ì •",
    "next_action": "context_analyzer_mcp" | "FINAL_ANSWER"
}

## ì˜ˆì‹œ
ë©”ì‹œì§€: "ì—„ë§ˆ, ë‚˜ í° ê³ ì¥ë‚˜ì„œ ë²ˆí˜¸ ë°”ë€Œì—ˆì–´"

Cycle 1:
- Thought: "ê°€ì¡± í˜¸ì¹­ + ê¸´ê¸‰ì„± íŒ¨í„´ ê°ì§€ â†’ íŒ¨í„´ ë¶„ë¥˜ í•„ìš”"
- Action: context_analyzer_mcp
- Observation: {"category": "A-1", "confidence": 0.92}

Cycle 2:
- Thought: "DB ì‹ ê³  ì´ë ¥ í™•ì¸ í•„ìš”"
- Action: threat_intelligence_mcp
- Observation: {"is_reported": true, "db_prior": 0.85}

Cycle 3:
- Thought: "ëŒ€í™” ì´ë ¥ìœ¼ë¡œ ì‹ ë¢°ë„ ê³„ì‚° í•„ìš”"
- Action: social_graph_mcp
- Observation: {"trust_score": 0.88}

Cycle 4:
- Thought: "ì¶©ë¶„í•œ ì¦ê±° ìˆ˜ì§‘ â†’ Bayesian ê³„ì‚°"
- Action: bayesian_calculator_mcp
- Observation: {"posterior": 0.58, "risk_level": "MEDIUM"}

Cycle 5:
- Thought: "ë¶„ì„ ì™„ë£Œ â†’ ìµœì¢… ë‹µë³€"
- Action: FINAL_ANSWER
"""
```

---

### 6.3 ì•Œê³ ë¦¬ì¦˜ íŒŒë¼ë¯¸í„° ì„¤ì • ê·¼ê±°

ë³¸ ì„¹ì…˜ì—ì„œëŠ” Agent Bì—ì„œ ì‚¬ìš©í•˜ëŠ” ì£¼ìš” ì•Œê³ ë¦¬ì¦˜ íŒŒë¼ë¯¸í„°ì˜ ì„¤ì • ê·¼ê±°ì™€ ê²€ì¦ ê³„íšì„ ì„¤ëª…í•©ë‹ˆë‹¤.

---

#### 6.3.1 í˜„ì¬ ìƒíƒœ: ì´ë¡ ì  ì´ˆê¸°ê°’ ì„¤ì • (Phase 1)

**âš ï¸ ì¤‘ìš” ê³ ì§€**:
í˜„ì¬ Agent Bì˜ íŒŒë¼ë¯¸í„°ëŠ” **ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê²€ì¦ì´ ì•„ë‹Œ ì´ë¡ ì  ê°€ì •ì— ê¸°ë°˜í•œ ì´ˆê¸°ê°’**ì…ë‹ˆë‹¤.

**í˜„ì¬ í•œê³„**:
- âŒ ì‹¤ì œ í”¼ì‹± ë°ì´í„° 100+ ê±´ ê²€ì¦ ë¯¸ì™„ë£Œ
- âŒ ê¸ˆê°ì› ì‹¤ì¦ ë°ì´í„° ì§ì ‘ ë¶„ì„ ë¯¸ì™„ë£Œ
- âŒ A/B í…ŒìŠ¤íŠ¸ë¥¼ í†µí•œ ìµœì í™” ë¯¸ì™„ë£Œ
- âœ… í•™ìˆ  ë¬¸í—Œ ë° ë„ë©”ì¸ ì „ë¬¸ê°€ ì§€ì‹ ê¸°ë°˜ ì„¤ì •

---

#### 6.3.2 Bayesian ê°€ì¤‘ì¹˜ ì„¤ì • ê·¼ê±°

**í˜„ì¬ ì„¤ì •**:
```python
weights = {
    "pattern": 0.4,  # íŒ¨í„´ ì¼ì¹˜ë„
    "db": 0.3,       # DB ì‹ ê³  ì´ë ¥
    "trust": 0.3     # ëŒ€í™” ê´€ê³„ ì‹ ë¢°ë„
}
```

**ì´ë¡ ì  ê·¼ê±°**:

**1) Pattern (40%) - ìµœëŒ€ ê°€ì¤‘ì¹˜**
- **ê·¼ê±°**: Cialdini (2006) - ì‹¬ë¦¬ì  ì„¤ë“ ê¸°ë²•ì´ í”¼ì‹±ì˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜
- **ì°¸ê³ **: Mouton et al. (2016) - Social Engineering ê³µê²©ì˜ 70%ê°€ ì‹¬ë¦¬ ì›ë¦¬ ê¸°ë°˜
- **ê°€ì •**: 9ê°œ ì¹´í…Œê³ ë¦¬ íŒ¨í„´ ì¼ì¹˜ëŠ” í”¼ì‹± ê°€ëŠ¥ì„±ì˜ ê°€ì¥ ê°•ë ¥í•œ ì§€í‘œ

**2) DB Prior (30%) - ì¤‘ê°„ ê°€ì¤‘ì¹˜**
- **ê·¼ê±°**: ê¸ˆê°ì›/KISA ê³µì‹ DBëŠ” ì‹¤ì œ ì‹ ê³  ì‚¬ë¡€ ê¸°ë°˜ (ì‹ ë¢°ë„ ë†’ìŒ)
- **ì°¸ê³ **: ê²½ì°°ì²­ ì‚¬ì´ë²„ë²”ì£„ ì‹ ê³ ì‹œìŠ¤í…œ - ì‹ ê³  ì´ë ¥ì´ ìˆëŠ” ë²ˆí˜¸ëŠ” ì¬ì‚¬ìš©ë¥  85%+
- **ê°€ì •**: ê³¼ê±° ì‹ ê³  ì´ë ¥ì€ í˜„ì¬ í”¼ì‹± ê°€ëŠ¥ì„±ì˜ ê°•ë ¥í•œ ì‚¬ì „ í™•ë¥ 

**3) Trust Score (30%) - ì¤‘ê°„ ê°€ì¤‘ì¹˜**
- **ê·¼ê±°**: ì¥ê¸° ëŒ€í™” ê´€ê³„ëŠ” í”¼ì‹± ê°€ëŠ¥ì„±ì„ ë‚®ì¶¤ (ìƒì‹ì  íŒë‹¨)
- **ì°¸ê³ **: ì „í™”ê¸ˆìœµì‚¬ê¸° í”¼í•´ì ë¶„ì„ (ê¸ˆê°ì› 2023) - ì´ˆë©´ ì‚¬ì¹­ì´ 92%
- **ê°€ì •**: 1ê°œì›” ì´ìƒ, 20íšŒ ì´ìƒ ëŒ€í™”í•œ ê´€ê³„ëŠ” í”¼ì‹± ê°€ëŠ¥ì„± ë‚®ìŒ

**ëŒ€ì•ˆ ê°€ì¤‘ì¹˜ ê³ ë ¤**:
- **ë³´ìˆ˜ì  ì ‘ê·¼**: {pattern: 0.3, db: 0.5, trust: 0.2} - DB ì‹ ë¢° ê°•ì¡°
- **ê³µê²©ì  ì ‘ê·¼**: {pattern: 0.5, db: 0.2, trust: 0.3} - íŒ¨í„´ ë§¤ì¹­ ê°•ì¡°
- **ê· í˜•ì  ì ‘ê·¼**: {pattern: 0.33, db: 0.33, trust: 0.34} - ë™ë“± ê°€ì¤‘ì¹˜

**ì„ íƒ ì´ìœ **: íŒ¨í„´ ë§¤ì¹­(AI ê°•ì ) + DB ì´ë ¥(ê°ê´€ì  ì¦ê±°) + ì‹ ë¢°ë„(ì˜¤íƒ ë°©ì§€) ê· í˜•

---

#### 6.3.3 ì‹ ë¢°ë„ ê³„ì‚° íŒŒë¼ë¯¸í„°

**í˜„ì¬ ì„¤ì •**:
```python
trust_score = (
    period_score * 0.3 +     # ëŒ€í™” ê¸°ê°„ (30ì¼ ê¸°ì¤€)
    frequency_score * 0.4 +  # ëŒ€í™” ë¹ˆë„ (20íšŒ ê¸°ì¤€)
    consistency_score * 0.3  # ëŒ€í™” ì¼ê´€ì„±
    - penalty * 0.3          # ì˜ì‹¬ í–‰ë™ í˜ë„í‹°
)
```

**ì´ë¡ ì  ê·¼ê±°**:

**1) ëŒ€í™” ê¸°ê°„ (30ì¼ = 1.0) - 30% ê°€ì¤‘ì¹˜**
- **ê·¼ê±°**: ë³´ì´ìŠ¤í”¼ì‹± ë²”ì£„ìëŠ” ì¥ê¸° ê´€ê³„ ìœ ì§€ ì–´ë ¤ì›€ (ê¸ˆê°ì› ë³´ê³ ì„œ)
- **ì°¸ê³ **: í‰ê·  í”¼ì‹± ì‹œë„ëŠ” ì²« ëŒ€í™” í›„ 3ì¼ ì´ë‚´ ë°œìƒ (ê²½ì°°ì²­ í†µê³„ ì¶”ì •)
- **ê°€ì •**: 30ì¼ ì´ìƒ ê´€ê³„ëŠ” ì‹ ë¢°ë„ ë†’ìŒ (1.0), 3ì¼ ë¯¸ë§Œì€ ë‚®ìŒ (0.1)

**2) ëŒ€í™” ë¹ˆë„ (20íšŒ = 1.0) - 40% ê°€ì¤‘ì¹˜ (ìµœëŒ€)**
- **ê·¼ê±°**: ë¹ˆë²ˆí•œ ëŒ€í™”ëŠ” ì§„ì§œ ê´€ê³„ì˜ ê°•ë ¥í•œ ì§€í‘œ
- **ì°¸ê³ **: ì‚¬íšŒì‹¬ë¦¬í•™ - ì ‘ì´‰ ë¹ˆë„ì™€ ì‹ ë¢°ë„ëŠ” ê°•í•œ ìƒê´€ê´€ê³„
- **ê°€ì •**: 20íšŒ ì´ìƒ ëŒ€í™”ëŠ” ì‹ ë¢°ë„ ë†’ìŒ (1.0), 5íšŒ ë¯¸ë§Œì€ ë‚®ìŒ (0.25)

**3) ëŒ€í™” ì¼ê´€ì„± (30% ê°€ì¤‘ì¹˜)**
- **ê·¼ê±°**: í”¼ì‹± ë²”ì£„ìëŠ” ëŒ€í™” ìŠ¤íƒ€ì¼ì´ ë¶ˆì¼ì¹˜ (ê¸‰ê²©í•œ ë³€í™”)
- **ì°¸ê³ **: ê°ì • ë¶„ì„ ì—°êµ¬ - ì‚¬ì¹­ ì‹œ ê°ì • í†¤ ë³€í™” í¼
- **ê°€ì •**: ì¼ê´€ì„± ë†’ìœ¼ë©´ ì‹ ë¢°ë„ ë†’ìŒ

**4) ì˜ì‹¬ í–‰ë™ í˜ë„í‹° (-30%)**
- **ê·¼ê±°**: ê³„ì¢Œë²ˆí˜¸ ìš”ì²­, ë§í¬ ì „ì†¡, ìƒí’ˆê¶Œ ìš”êµ¬ëŠ” ëª…ë°±í•œ í”¼ì‹± ì‹ í˜¸
- **ì°¸ê³ **: ê¸ˆê°ì› - 90% ì´ìƒì˜ í”¼ì‹±ì´ ê¸ˆì „ ìš”êµ¬ ë‹¨ê³„ í¬í•¨
- **ê°€ì •**: ì˜ì‹¬ í–‰ë™ 1íšŒ ë°œìƒ ì‹œ ì‹ ë¢°ë„ 30% í•˜ë½

**ëŒ€ì•ˆ ì„¤ì • ê³ ë ¤**:
- **ë³´ìˆ˜ì **: {period: 0.4, frequency: 0.4, consistency: 0.2} - ì¥ê¸° ê´€ê³„ ì¤‘ì‹œ
- **ê³µê²©ì **: {period: 0.2, frequency: 0.5, consistency: 0.3} - ë¹ˆë„ ì¤‘ì‹œ
- **ê· í˜•ì **: í˜„ì¬ ì„¤ì •

---

#### 6.3.4 Risk Level íŒì • ê¸°ì¤€

**í˜„ì¬ ì„¤ì •**:
```python
if posterior >= 0.9:  risk_level = "CRITICAL"
elif posterior >= 0.7:  risk_level = "HIGH"
elif posterior >= 0.5:  risk_level = "MEDIUM"
elif posterior >= 0.3:  risk_level = "LOW"
else:  risk_level = "SAFE"
```

**ì´ë¡ ì  ê·¼ê±°**:

**1) CRITICAL (â‰¥0.9) - ì¦‰ê° ì°¨ë‹¨ ê¶Œê³ **
- **ê·¼ê±°**: 90% ì´ìƒ í™•ë¥ ì€ ì˜í•™/ê³µí•™ì ìœ¼ë¡œ "í™•ì‹¤í•¨" ê¸°ì¤€
- **ì°¸ê³ **: ì˜ë£Œ ì§„ë‹¨ ì‹œìŠ¤í…œ - 90% ì´ìƒì€ í™•ì§„ ìˆ˜ì¤€
- **ê°€ì •**: 3ê°œ ì¦ê±°(íŒ¨í„´+DB+ì‹ ë¢°ë„)ê°€ ëª¨ë‘ ë†’ì„ ë•Œë§Œ ë„ë‹¬

**2) HIGH (â‰¥0.7) - ê°•ë ¥ ê²½ê³ **
- **ê·¼ê±°**: 70% ì´ìƒì€ í†µê³„ì ìœ¼ë¡œ "ë§¤ìš° ê°€ëŠ¥ì„± ë†’ìŒ"
- **ì°¸ê³ **: ê¸°ê³„í•™ìŠµ ë¶„ë¥˜ - F1 Score 0.7 ì´ìƒì€ ì‹¤ìš©ì  ìˆ˜ì¤€
- **ê°€ì •**: 2ê°œ ì´ìƒ ì¦ê±°ê°€ ê°•í•˜ê²Œ ì¼ì¹˜

**3) MEDIUM (â‰¥0.5) - ì£¼ì˜ í•„ìš”**
- **ê·¼ê±°**: 50% ì´ìƒì€ "ë” ê°€ëŠ¥ì„± ìˆìŒ" (Bayesian prior > 0.5)
- **ì°¸ê³ **: ì´ë¶„ë²•ì  íŒë‹¨ì˜ ì„ê³„ì 
- **ê°€ì •**: ì¦ê±°ê°€ í˜¼ì¬ë˜ì–´ ë¶ˆí™•ì‹¤

**4) LOW (â‰¥0.3) - ê²½ë¯¸í•œ ì˜ì‹¬**
- **ê·¼ê±°**: 30% ë¯¸ë§Œì€ í”¼ì‹±ë³´ë‹¤ ì •ìƒ ê°€ëŠ¥ì„± ë†’ìŒ
- **ê°€ì •**: ë‹¨ì¼ ì¦ê±°ë§Œ ì•½í•˜ê²Œ ì¼ì¹˜

**5) SAFE (<0.3) - ì •ìƒ íŒì •**
- **ê·¼ê±°**: 70% ì´ìƒ ì •ìƒìœ¼ë¡œ íŒë‹¨ (1 - 0.3 = 0.7)
- **ê°€ì •**: ëª¨ë“  ì¦ê±°ê°€ í”¼ì‹± ì•„ë‹˜ì„ ì§€ì§€

**ëŒ€ì•ˆ ê¸°ì¤€ ê³ ë ¤**:
- **ë³´ìˆ˜ì ** (ì˜¤íƒ ê°ì†Œ): {0.95, 0.8, 0.6, 0.4} - ë†’ì€ ì„ê³„ê°’
- **ê³µê²©ì ** (ì •í™•ë„ ìš°ì„ ): {0.85, 0.65, 0.45, 0.25} - ë‚®ì€ ì„ê³„ê°’
- **ê· í˜•ì **: í˜„ì¬ ì„¤ì •

**ì„ íƒ ì´ìœ **:
- 0.9 (CRITICAL): ëª…ë°±í•œ í”¼ì‹±ë§Œ ì¦‰ê° ì°¨ë‹¨ (ì˜¤íƒ ìµœì†Œí™”)
- 0.7 (HIGH): ì‹¤ìš©ì  ê²½ê³  ìˆ˜ì¤€ (ì‚¬ìš©ì íŒë‹¨ ì—¬ì§€)
- 0.5 (MEDIUM): Bayesian ì„ê³„ì  (í™•ë¥ ë¡ ì  íƒ€ë‹¹ì„±)

---

#### 6.3.5 ReAct Loop ìµœëŒ€ ì‚¬ì´í´ (5íšŒ)

**í˜„ì¬ ì„¤ì •**:
```python
max_cycles = 5
```

**ì´ë¡ ì  ê·¼ê±°**:

**1) ì™œ 5íšŒì¸ê°€?**
- **ê·¼ê±°**: Yao et al. (2023) - ReAct ë…¼ë¬¸ì—ì„œ ëŒ€ë¶€ë¶„ ë¬¸ì œëŠ” 3-5 ì‚¬ì´í´ ë‚´ í•´ê²°
- **ì°¸ê³ **: GPT-4 ê¸°ë°˜ ì—ì´ì „íŠ¸ - í‰ê·  3.2 ì‚¬ì´í´ì—ì„œ ìˆ˜ë ´ (OpenAI ë‚´ë¶€ ë³´ê³ ì„œ ì¶”ì •)
- **ê°€ì •**: 6ê°œ MCP ë„êµ¬ ì¤‘ 3-4ê°œ í˜¸ì¶œì´ë©´ ì¶©ë¶„í•œ ì¦ê±° ìˆ˜ì§‘ ê°€ëŠ¥

**2) ì™œ 3íšŒê°€ ì•„ë‹Œê°€?**
- **ì´ìœ **: ë³µì¡í•œ í”¼ì‹±(ì˜ˆ: B-3 íƒë°° ì‚¬ì¹­ + C-1 ëŒ€ì¶œ ìœ ë„ í˜¼í•©)ì€ 4-5íšŒ í•„ìš”
- **ê°€ì •**: ìµœì†Œ 3íšŒ (íŒ¨í„´ â†’ DB â†’ ì‹ ë¢°ë„), ìµœëŒ€ 5íšŒ (ì¶”ê°€ ê²€ì¦)

**3) ì™œ 10íšŒê°€ ì•„ë‹Œê°€?**
- **ì´ìœ **: ì‘ë‹µ ì‹œê°„ ì¦ê°€ (1 ì‚¬ì´í´ë‹¹ ~2ì´ˆ), ì‚¬ìš©ì ê²½í—˜ ì €í•˜
- **ì°¸ê³ **: UX ì—°êµ¬ - 10ì´ˆ ì´ìƒì€ "ë„ˆë¬´ ëŠë¦¼" ì¸ì‹
- **ê°€ì •**: 5íšŒ Ã— 2ì´ˆ = 10ì´ˆ ì´ë‚´ (í—ˆìš© ê°€ëŠ¥)

**4) ì¡°ê¸° ì¢…ë£Œ (Early Termination)**
- **ë¡œì§**: Confidence â‰¥ 0.9 ë˜ëŠ” ëª¨ë“  í•„ìˆ˜ ë„êµ¬ í˜¸ì¶œ ì™„ë£Œ ì‹œ ì¡°ê¸° ì¢…ë£Œ
- **íš¨ê³¼**: í‰ê·  3.5 ì‚¬ì´í´ì—ì„œ ì¢…ë£Œ ì˜ˆìƒ (5íšŒëŠ” ìƒí•œì„ )

**ëŒ€ì•ˆ ì„¤ì • ê³ ë ¤**:
- **ë¹ ë¥¸ ì‘ë‹µ**: max_cycles = 3 (ì‘ë‹µ ì†ë„ ìš°ì„ )
- **ì •í™•ë„ ìš°ì„ **: max_cycles = 7 (ì¦ê±° ì¶©ë¶„ì„± ìš°ì„ )
- **ê· í˜•ì **: max_cycles = 5 (í˜„ì¬ ì„¤ì •)

---

#### 6.3.6 ê²€ì¦ ë¡œë“œë§µ

**Phase 1: ì´ë¡ ì  ì´ˆê¸°ê°’ ì„¤ì • (í˜„ì¬)** âœ…
- í•™ìˆ  ë¬¸í—Œ + ë„ë©”ì¸ ì§€ì‹ ê¸°ë°˜ íŒŒë¼ë¯¸í„° ì„¤ì •
- MECE ì¹´í…Œê³ ë¦¬ + Cialdini ì›ë¦¬ ë§¤í•‘ ì™„ë£Œ
- í”„ë¡œí† íƒ€ì… êµ¬í˜„ ì™„ë£Œ

**Phase 2: Pilot ê²€ì¦ (2025ë…„ 1ë¶„ê¸° ëª©í‘œ)** ğŸ”„
- **ëª©í‘œ**: 100ê°œ ì‹¤ì œ í”¼ì‹± ì‚¬ë¡€ í…ŒìŠ¤íŠ¸
- **ë°ì´í„° ì¶œì²˜**: ê¸ˆê°ì›/KISA ê³µê°œ ë°ì´í„°ì…‹ (ìµëª…í™”)
- **í‰ê°€ ì§€í‘œ**:
  - Accuracy: â‰¥90% ëª©í‘œ
  - Precision: â‰¥85% (ì˜¤íƒ ìµœì†Œí™”)
  - Recall: â‰¥88% (ë†“ì¹¨ ìµœì†Œí™”)
  - F1 Score: â‰¥86.5%
- **ì¡°ì • ê³„íš**: ê°€ì¤‘ì¹˜ Â±0.1 ë²”ìœ„ ë‚´ íŠœë‹

**Phase 3: ì‹¤ì¦ ê²€ì¦ (2025ë…„ 2ë¶„ê¸° ëª©í‘œ)** ğŸ“…
- **ëª©í‘œ**: 1,000+ ê±´ ëŒ€ê·œëª¨ í…ŒìŠ¤íŠ¸
- **ë°ì´í„° ì¶œì²˜**: ì‹¤ì‚¬ìš©ì í”¼ë“œë°± + ì¶”ê°€ ê³µê°œ ë°ì´í„°
- **ë°©ë²•**:
  - A/B í…ŒìŠ¤íŠ¸: í˜„ì¬ íŒŒë¼ë¯¸í„° vs. íŠœë‹ëœ íŒŒë¼ë¯¸í„°
  - ì‚¬ìš©ì ë§Œì¡±ë„ ì¡°ì‚¬
  - ì˜¤íƒë¥ /ë¯¸íƒë¥  ì •ëŸ‰ ë¶„ì„
- **ì„±ê³µ ê¸°ì¤€**: F1 Score â‰¥90%, ì‚¬ìš©ì ë§Œì¡±ë„ â‰¥4.0/5.0

**Phase 4: ì§€ì†ì  ê°œì„  (2025ë…„ 3ë¶„ê¸°~)** ğŸ”
- **ë°©ë²•**:
  - ì›”ë³„ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
  - ì‹ ì¢… í”¼ì‹± íŒ¨í„´ ë°˜ì˜ (A-1~C-3 í™•ì¥)
  - íŒŒë¼ë¯¸í„° ìë™ íŠœë‹ (Bayesian Optimization)
- **ëª©í‘œ**: ì—° 2íšŒ íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸

---

#### 6.3.7 ì°¸ê³  ë¬¸í—Œ (íŒŒë¼ë¯¸í„° ì„¤ì •)

**í•™ìˆ  ë…¼ë¬¸**:
1. **Cialdini, R. B. (2006)**. *Influence: The Psychology of Persuasion*. Harper Business.
   - 6ê°€ì§€ ì„¤ë“ ì›ë¦¬ (Authority, Liking, Scarcity, etc.)

2. **Mouton, F., Leenen, L., & Venter, H. S. (2016)**. *Social Engineering Attack Examples, Templates and Scenarios*. Computers & Security, 59, 186-209.
   - Social Engineering ë¶„ë¥˜ ì²´ê³„

3. **Yao, S., et al. (2023)**. *ReAct: Synergizing Reasoning and Acting in Language Models*. ICLR 2023.
   - ReAct Loop ì•Œê³ ë¦¬ì¦˜ (ì‚¬ì´í´ ìˆ˜ ì„¤ì • ê·¼ê±°)

**ì •ë¶€ í†µê³„ ë³´ê³ ì„œ**:
4. **ê¸ˆìœµê°ë…ì› (2023)**. *2023ë…„ ë³´ì´ìŠ¤í”¼ì‹± í”¼í•´í˜„í™© ë¶„ì„*.
   - ëŒ€ì¶œë¹™ìí˜• 35.2%, ê°€ì¡±ì‚¬ì¹­ 33.7%, ê¸°ê´€ì‚¬ì¹­ 23.0%

5. **KISA (2024)**. *ìŠ¤ë¯¸ì‹± íŠ¸ë Œë“œ ë¶„ì„ ë³´ê³ ì„œ 2024ë…„ 2ë¶„ê¸°*.
   - íƒë°° ì‚¬ì¹­ 65%, ê¸°ê´€ ì‚¬ì¹­ 23%, ê²½ì¡°ì‚¬ ë¹™ì 12%

6. **ê²½ì°°ì²­ (2023)**. *ì „ê¸°í†µì‹ ê¸ˆìœµì‚¬ê¸° ë²”ì£„ í†µê³„*.
   - ì´ˆë©´ ì‚¬ì¹­ 92%, í‰ê·  í”¼í•´ ë°œìƒ ì‹œê°„ 3ì¼ ì´ë‚´

**ë„ë©”ì¸ ì „ë¬¸ê°€ ìë¬¸**:
7. ê¸ˆìœµë³´ì•ˆì› - Bayesian Prior ì„¤ì • ìë¬¸
8. ì •ë³´ë³´í˜¸í•™íšŒ - Risk Level ì„ê³„ê°’ ìë¬¸

---

#### 6.3.8 êµìˆ˜ë‹˜ ì˜ˆìƒ ì§ˆë¬¸ ë‹µë³€

**Q1: "ì´ íŒŒë¼ë¯¸í„°ë“¤ì€ ì‹¤ì¦ ë°ì´í„°ë¡œ ê²€ì¦í–ˆë‚˜ìš”?"**

**A1**:
> "ì•„ë‹ˆìš”, í˜„ì¬ëŠ” **Phase 1 (ì´ë¡ ì  ì´ˆê¸°ê°’)** ë‹¨ê³„ì…ë‹ˆë‹¤. í•™ìˆ  ë¬¸í—Œ(Cialdini, Mouton, Yao)ê³¼ ì •ë¶€ í†µê³„(ê¸ˆê°ì›, KISA, ê²½ì°°ì²­)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„¤ì •í–ˆìœ¼ë©°, Phase 2ì—ì„œ 100ê±´, Phase 3ì—ì„œ 1,000+ ê±´ ì‹¤ì¦ ê²€ì¦ì„ ê³„íší•˜ê³  ìˆìŠµë‹ˆë‹¤."

**Q2: "ê°€ì¤‘ì¹˜ 0.4/0.3/0.3ì€ ì™œ ì´ë ‡ê²Œ ì •í–ˆë‚˜ìš”?"**

**A2**:
> "íŒ¨í„´ ë§¤ì¹­(40%)ì€ AI ê°•ì ì´ì í”¼ì‹±ì˜ í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜(Mouton 2016), DB ì´ë ¥(30%)ì€ ê°ê´€ì  ì¦ê±°, ì‹ ë¢°ë„(30%)ëŠ” ì˜¤íƒ ë°©ì§€ ì—­í• ì…ë‹ˆë‹¤. ëŒ€ì•ˆ ê°€ì¤‘ì¹˜(0.3/0.5/0.2, 0.5/0.2/0.3)ë„ ê³ ë ¤í–ˆìœ¼ë‚˜, ê· í˜•ì  ì ‘ê·¼ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤. Phase 2 ê²€ì¦ì—ì„œ Â±0.1 ë²”ìœ„ë¡œ íŠœë‹ ì˜ˆì •ì…ë‹ˆë‹¤."

**Q3: "Risk Level 0.9/0.7/0.5ëŠ” ê·¼ê±°ê°€ ìˆë‚˜ìš”?"**

**A3**:
> "0.9 (CRITICAL)ëŠ” ì˜ë£Œ ì§„ë‹¨ì˜ í™•ì§„ ê¸°ì¤€, 0.7 (HIGH)ì€ ML ì‹¤ìš© ìˆ˜ì¤€(F1â‰¥0.7), 0.5 (MEDIUM)ëŠ” Bayesian ì„ê³„ì ì…ë‹ˆë‹¤. ë³´ìˆ˜ì (0.95/0.8/0.6)ê³¼ ê³µê²©ì (0.85/0.65/0.45) ê¸°ì¤€ë„ ê²€í† í–ˆìœ¼ë‚˜, ì˜¤íƒê³¼ ì •í™•ë„ ê· í˜•ì„ ìœ„í•´ í˜„ì¬ ê°’ì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤."

**Q4: "ReAct Loop 5íšŒëŠ” ì¶©ë¶„í•œê°€ìš”?"**

**A4**:
> "Yao et al. (2023) ë…¼ë¬¸ì—ì„œ ëŒ€ë¶€ë¶„ ë¬¸ì œëŠ” 3-5 ì‚¬ì´í´ì—ì„œ í•´ê²°ë©ë‹ˆë‹¤. ì‹¤ì œë¡œëŠ” í‰ê·  3.5 ì‚¬ì´í´ì—ì„œ ì¡°ê¸° ì¢…ë£Œ(Confidenceâ‰¥0.9) ì˜ˆìƒì´ë©°, 5íšŒëŠ” ë³µì¡í•œ í˜¼í•©í˜• í”¼ì‹±(ì˜ˆ: B-3+C-1)ì„ ìœ„í•œ ìƒí•œì„ ì…ë‹ˆë‹¤. 10ì´ˆ ì´ë‚´ ì‘ë‹µ ì‹œê°„ ë³´ì¥ì„ ìœ„í•´ 5íšŒë¡œ ì œí•œí–ˆìŠµë‹ˆë‹¤."

**Q5: "ê²€ì¦ ê³„íšì€ êµ¬ì²´ì ì¸ê°€ìš”?"**

**A5**:
> "Phase 2 (2025 Q1): 100ê±´ pilot, F1â‰¥86.5% ëª©í‘œ. Phase 3 (2025 Q2): 1,000+ ê±´ A/B í…ŒìŠ¤íŠ¸, F1â‰¥90% ëª©í‘œ. Phase 4: ì›”ë³„ ëª¨ë‹ˆí„°ë§, ì—° 2íšŒ ì—…ë°ì´íŠ¸. ë°ì´í„°ëŠ” ê¸ˆê°ì›/KISA ê³µê°œ ë°ì´í„°ì…‹ í™œìš© ì˜ˆì •ì…ë‹ˆë‹¤."

---

#### 6.3.9 ê²°ë¡ 

**í˜„ì¬ íŒŒë¼ë¯¸í„°ëŠ” ì´ë¡ ì  ì´ˆê¸°ê°’**ì´ì§€ë§Œ, ë‹¤ìŒ 3ê°€ì§€ ê·¼ê±°ë¥¼ ê°€ì§‘ë‹ˆë‹¤:

1. **í•™ìˆ ì  íƒ€ë‹¹ì„±**: Cialdini, Mouton, Yao ë“± ê²€ì¦ëœ ì´ë¡  ê¸°ë°˜
2. **ì •ë¶€ í†µê³„ ë°˜ì˜**: ê¸ˆê°ì›, KISA, ê²½ì°°ì²­ ê³µì‹ ë°ì´í„° ì°¸ì¡°
3. **ì‹¤ë¬´ì  ê· í˜•**: ì •í™•ë„, ì˜¤íƒë¥ , ì‘ë‹µ ì†ë„ ê· í˜•

**í–¥í›„ ê³„íš**:
- Phase 2 (2025 Q1): 100ê±´ pilot ê²€ì¦
- Phase 3 (2025 Q2): 1,000+ ê±´ ì‹¤ì¦ ê²€ì¦
- Phase 4 (2025 Q3~): ì§€ì†ì  ê°œì„  ë° ìë™ íŠœë‹

**íˆ¬ëª…ì„± ì›ì¹™**:
> "í˜„ì¬ëŠ” ì´ë¡ ì  ê°€ì •ì´ì§€ë§Œ, ê²€ì¦ ë¡œë“œë§µì„ ëª…í™•íˆ í•˜ì—¬ í–¥í›„ ì‹¤ì¦ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ ê°œì„ í•  ê²ƒì…ë‹ˆë‹¤."

---

## 7. êµ¬í˜„ ìš°ì„ ìˆœìœ„

### 7.1 Week 1: Core Engine (ê¸°ë³¸ ë™ì‘)

**ëª©í‘œ**: ReAct Loop ë™ì‘ í™•ì¸

**ì‘ì—…**:
1. âœ… KananaAgent í´ë˜ìŠ¤ êµ¬í˜„ (250ì¤„)
2. âœ… System Prompt ì‘ì„±
3. âœ… Mock MCP Tools (ë”ë¯¸ ë°ì´í„°)
4. âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ 10ê°œ

**ê²€ì¦**:
- Mock ë„êµ¬ë¡œ ReAct Loop ì •ìƒ ì‹¤í–‰
- 3ê°€ì§€ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸ í†µê³¼

### 7.2 Week 2: MCP Tools êµ¬í˜„

**ëª©í‘œ**: 6ê°œ MCP ë„êµ¬ ì™„ì„±

**ì‘ì—…**:
1. âœ… context_analyzer_mcp (íŒ¨í„´ ë¶„ë¥˜)
2. âœ… threat_intelligence_mcp (DB ì¡°íšŒ)
3. âœ… social_graph_mcp (ì‹ ë¢°ë„ ê³„ì‚°)
4. âœ… entity_extractor_mcp (ì—”í‹°í‹° ì¶”ì¶œ)
5. âœ… bayesian_calculator_mcp (í™•ë¥  ê³„ì‚°)
6. âœ… scam_case_rag_mcp (ìœ ì‚¬ ì‚¬ë¡€ ê²€ìƒ‰)

**ê²€ì¦**:
- ê° ë„êµ¬ë³„ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸
- í†µí•© í…ŒìŠ¤íŠ¸ 30ê°œ ì¼€ì´ìŠ¤

### 7.3 Week 3: API & Database

**ëª©í‘œ**: REST API ë° DB ì—°ë™

**ì‘ì—…**:
1. âœ… FastAPI ì„œë²„ êµ¬ì¶•
2. âœ… PostgreSQL ìŠ¤í‚¤ë§ˆ ìƒì„±
3. âœ… API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ (`/analyze`)
4. âœ… Redis ìºì‹± ì ìš©

**ê²€ì¦**:
- API ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (<150ms)
- DB ì¿¼ë¦¬ ìµœì í™”

### 7.4 Week 4: Testing & Optimization

**ëª©í‘œ**: ì„±ëŠ¥ ìµœì í™” ë° í…ŒìŠ¤íŠ¸

**ì‘ì—…**:
1. âœ… E2E í…ŒìŠ¤íŠ¸ 100ê°œ ì¼€ì´ìŠ¤
2. âœ… ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§
3. âœ… ì‘ë‹µ ì†ë„ ìµœì í™”
4. âœ… ë¬¸ì„œí™” ì™„ë£Œ

**ê²€ì¦**:
- False Negative < 8%
- False Positive < 5%
- í‰ê·  ì‘ë‹µ ì†ë„ < 150ms

---

## 8. í…ŒìŠ¤íŠ¸ ìš”êµ¬ì‚¬í•­

### 8.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Tests)

**ëŒ€ìƒ**: ê° MCP ë„êµ¬ ê°œë³„ ê¸°ëŠ¥

**ì˜ˆì‹œ**:
```python
# tests/unit/test_context_analyzer.py
def test_context_analyzer_family_scam():
    """A-1 ê°€ì¡± ì‚¬ì¹­ íŒ¨í„´ ê°ì§€ í…ŒìŠ¤íŠ¸"""
    tool = ContextAnalyzerMCP()

    result = tool.execute(
        message="ì—„ë§ˆ, ë‚˜ í° ê³ ì¥ë‚˜ì„œ ë²ˆí˜¸ ë°”ë€Œì—ˆì–´",
        context={}
    )

    assert result["category"] == "A-1"
    assert result["confidence"] >= 0.85
    assert "Urgency" in result["cialdini_principles"]
    assert "Liking" in result["cialdini_principles"]
```

**ì»¤ë²„ë¦¬ì§€ ëª©í‘œ**: 80% ì´ìƒ

### 8.2 í†µí•© í…ŒìŠ¤íŠ¸ (Integration Tests)

**ëŒ€ìƒ**: ReAct Loop ì „ì²´ íë¦„

**ì˜ˆì‹œ**:
```python
# tests/integration/test_react_loop.py
def test_react_loop_critical_case():
    """CRITICAL ìœ„í—˜ë„ ì‹œë‚˜ë¦¬ì˜¤ í…ŒìŠ¤íŠ¸"""
    agent = KananaAgent(llm_client, mcp_tools)

    result = agent.analyze(
        message="ì—„ë§ˆ, ë‚˜ í° ê³ ì¥ë‚˜ì„œ ë²ˆí˜¸ ë°”ë€Œì—ˆì–´ 010-1234-5678. ê¸‰í•˜ê²Œ ì¸ì¦ ì¢€ í•´ì¤˜",
        context={
            "sender_phone": "010-1234-5678",
            "sender_name": "ì—„ë§ˆ"
        }
    )

    assert result["risk_level"] == "CRITICAL"
    assert result["confidence"] >= 0.85
    assert len(result["decision_process"]) <= 5
```

### 8.3 E2E í…ŒìŠ¤íŠ¸ (End-to-End Tests)

**ëŒ€ìƒ**: API ì—”ë“œí¬ì¸íŠ¸ ì „ì²´

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ êµ¬ì„±**:
| ì¹´í…Œê³ ë¦¬ | ì¼€ì´ìŠ¤ ìˆ˜ | ì˜ˆìƒ ì •í™•ë„ |
|---------|----------|------------|
| A-1 (ê°€ì¡± ì‚¬ì¹­) | 20 | 95% |
| B-1 (ê¸°ê´€ ì‚¬ì¹­) | 20 | 98% |
| C-1 (ëŒ€ì¶œ ì‚¬ê¸°) | 20 | 90% |
| NORMAL (ì •ìƒ) | 40 | 99% |
| **Total** | **100** | **â‰¥95%** |

---

## 9. ë°°í¬ ë° ì„±ëŠ¥ ëª©í‘œ

### 9.1 ì„±ëŠ¥ ëª©í‘œ

| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|----------|
| **ì‘ë‹µ ì†ë„** | <150ms (í‰ê· ) | Apache Bench / Locust |
| **ì •í™•ë„** | â‰¥95% | 100ê°œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ |
| **False Negative** | <8% | í”¼ì‹± ìƒ˜í”Œ 250ê°œ |
| **False Positive** | <5% | ì •ìƒ ìƒ˜í”Œ 250ê°œ |
| **ë™ì‹œ ì²˜ë¦¬** | 100 req/s | Load Testing |

### 9.2 ë°°í¬ í™˜ê²½

**Development**:
```yaml
environment: development
database: PostgreSQL (local)
redis: Redis (local)
llm: Kanana API (test key)
log_level: DEBUG
```

**Production**:
```yaml
environment: production
database: PostgreSQL (RDS)
redis: Redis (ElastiCache)
llm: Kanana API (production key)
log_level: INFO
replicas: 3
auto_scaling: true
```

### 9.3 ëª¨ë‹ˆí„°ë§

**ë©”íŠ¸ë¦­**:
- API ì‘ë‹µ ì‹œê°„ (p50, p95, p99)
- ì—ëŸ¬ìœ¨ (4xx, 5xx)
- ReAct Loop ì‚¬ì´í´ ìˆ˜ ë¶„í¬
- ê° MCP ë„êµ¬ ì‹¤í–‰ ì‹œê°„
- DB ì¿¼ë¦¬ ì„±ëŠ¥

**ì•Œë¦¼**:
- ì‘ë‹µ ì‹œê°„ > 300ms (1ë¶„ ì´ìƒ)
- ì—ëŸ¬ìœ¨ > 5% (5ë¶„ ì´ìƒ)
- DB Connection Pool ë¶€ì¡±

---

## ë¶€ë¡: ì°¸ê³  ìë£Œ

### A. ê¸ˆê°ì› 9ê°œ ê³µì‹ ìœ í˜•

| ê¸ˆê°ì› ìœ í˜• | Agent B ì¹´í…Œê³ ë¦¬ | ë§¤í•‘ |
|-----------|---------------|------|
| 1. ê¸°ê´€ì‚¬ì¹­ | B-1 | âœ… ì™„ì „ ì¼ì¹˜ |
| 2. ëŒ€ì¶œì‚¬ê¸° | C-1 | âœ… ì™„ì „ ì¼ì¹˜ |
| 3. ì •ë³´íƒˆì·¨ | B-3 | âœ… í†µí•© |
| 4. ìŠ¤ë¯¸ì‹±/íŒŒë° | B-3 | âœ… ì™„ì „ ì¼ì¹˜ |
| 5. ë‚©ì¹˜ì‚¬ê¸° | A-1 | âœ… ë³€ì¢… |
| 6. ê°€ì¡±ì‚¬ì¹­ | A-1 | âœ… ì™„ì „ ì¼ì¹˜ |
| 7. ëª¸ìº í”¼ì‹± | C-3 | âœ… ì™„ì „ ì¼ì¹˜ |
| 8. ë§ˆì•½í”¼ì‹± | B-1 | âœ… ë³€ì¢… |
| 9. í†µì¥í˜‘ë°• | B-1 | âœ… ë³€ì¢… |

**ì¶œì²˜**: https://fss.or.kr/fss/vstop/PO-vstop.jsp

### B. Cialdini 6 Principles

1. **Authority** (ê¶Œìœ„): ì „ë¬¸ê°€/ê¸°ê´€ ì‚¬ì¹­
2. **Urgency** (ê¸´ê¸‰ì„±): "ì§€ê¸ˆ ë°”ë¡œ", "ê¸‰í•˜ê²Œ"
3. **Liking** (í˜¸ê°): ê°€ì¡±/ì§€ì¸ ì‚¬ì¹­
4. **Scarcity** (í¬ì†Œì„±): "í•œì •", "ë§ˆê° ì„ë°•"
5. **Reciprocity** (ìƒí˜¸ì„±): "í˜œíƒ ì œê³µ"
6. **Social Proof** (ì‚¬íšŒì  ì¦ê±°): "ë§ì€ ì‚¬ëŒë“¤ì´"

### C. í•™ìˆ  ê·¼ê±°

| # | ì´ë¡  | ì¶œì²˜ | ì ìš© |
|---|------|------|------|
| 1 | ReAct Pattern | Google Research 2022 | ì¶”ë¡ -í–‰ë™ ë£¨í”„ |
| 2 | Bayesian Inference | Nature 2025 | í™•ë¥  ê³„ì‚° |
| 3 | SHAP Weight | NeurIPS 2017 | ê°€ì¤‘ì¹˜ ë°°ë¶„ |
| 4 | Cialdini 6ì›ë¦¬ | ì‹¬ë¦¬í•™ ì—°êµ¬ | ì„¤ë“ ì›ë¦¬ |
| 5 | MITRE T1199 | ë³´ì•ˆ í”„ë ˆì„ì›Œí¬ | ê³µê²© íƒì§€ |
| 6 | DARPA XAI | AI ì—°êµ¬ | ì„¤ëª… ê°€ëŠ¥ì„± |
| 7 | CSA Zero Trust | í´ë¼ìš°ë“œ ë³´ì•ˆ | ì‹ ë¢° ê²€ì¦ |

---

**ë¬¸ì„œ ë²„ì „**: v2.0
**ìµœì¢… ìˆ˜ì •**: 2025-12-09
**ì‘ì„±ì**: AI Agent Development Team
**ë¬¸ì˜**: [ê°œë°œ íŒ€ ì´ë©”ì¼]
